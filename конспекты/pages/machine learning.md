- [[neural network]]
- В работе ([[Hoerandel]], [[Khakurdikar]] ) используется машинное обучение для классификации нейтрино и фона. Т.е. 1 или 0, как-то так?
  collapsed:: true
	- TODO [#A] разобраться
	- Используются данные, в которых приведены энергия, зенитный угол, параметры для фита (их 6, a,b,c,d,e,f), сигнал от мюона (log10 (S[^1]/ VEM)), количество сработавших станций и тип первичной частицы.
	- Для обучения на вход подаются параметры сигнала от мюона и числа станций. Они были выбраны потому, что именно они важны для того, чтобы разделить нейтрино от адронов. Параметры для фита - это параметры, которые подбирает модель. Данные были разделены на 80 и 20, обучающая и тестовая выборки, соответственно.
	- Перед началом процесса обучения модели необходимо задать гиперпараметры. Для Random Forest, эти гиперпараметры определяют индивидуальные деревья и как они работают в связке. Определяется целый ряд гиперпараметров, такие как число деревьев (n_estimators), максимальная глубина (max_depth), и минимальное число событий для разделения звена (min_samples_split) и для листа (min_samples_leaf). Затем используется кросс-валидация, чтобы выбрать наиболее подходящие гиперпараметры с минимальными ошибками. Большее количество деревьев (n_estimator) позволяет улучшить работу модели, увеличивает точность, уменьшает дисперсию. Но большее количество деревьев ведет к более длительной работе модели, как обучения, так и самого определения. В работе были использованы 50, 100 и 200 деревьев.
	- Для оценки эффективности сплитов используются два параметра, примесь (критерий) Джини [^2] и информационная энтропия [^3]. Критерий Джини является мерой, насколько случайно выбранный элемент из набора неверное помечается, если он случайным образом помечается согласно распределению меток в подмножестве. Информационная энтропия измеряет неопределенность и показывает непредсказуемость меток.
	- Глубина дерева показывает комплексность и определяется наибольшим числом внутренних звеньев от корня к самому дальнему листу. С увеличением глубины увеличивается точность, но, также, появляется опасность оверфита.
	- [^1] $$S = \sum_{i} S_{i} \times \left( \frac{R_{i}}{R_{ref}}\right)^{b}$$, где
	- S_{i} - сигнал на i-той станции на расстоянии $$R_{i}$$ от оси
	- и R_{ref} = 3500 м, который был взят из размеров наклонного ливня. Степень b - была взята равной 4, чтобы максимального разделить гамма-кванты от адронов.
	- [^2] Breiman, Leo, Friedman, Jerome, Olshen, Richard A., & Stone, Charles J. (1984). Classifica- tion and Regression Trees.
	- [^3] Shannon, Claude E. (1948). A Mathematical Theory of Communication. Bell System Technical Journal, 27(3), 379–423