- Быстрое развитие методов использующих различные виды искусственных нейросетей дало разные названия типа "машинного обучения" "глубокого обучения" и "ИИ". Некоторые используют эти три названия как синонимы, но авторы считают, что важно их различать.
- Машинное обучение это продолжение статистических численных методов, поэтому цели и задачи у него такие же. Автор называет такой подход, который не использует искусственные нейросети **классическим машинными обучением**. Одни из самых распространенных методов машинного обучения является линейная регрессия, которая вот уже несколько десятков лет успешно применятся в Астрофизике.
- С развитием современных методов регистрации, также повысилось требование к скорости и качеству обработки. А т.к. промышленные уже готовые решения не достаточны для задач физики, потому что мало найти паттерны в данных и предсказывать их, но необходимо и объяснять результаты. Поэтому астрофизика выдвигает следующие требования к современным моделям машинного обучения:
	- **Масштабируемость.** Модель должна быть достаточно гибкой, чтобы работать с миллиардами данных, с десятками миллионов или даже десятками тысяч. При этом точность и скорость работы должны быть достаточно высокими.
	- **Обобщаемость**. Модель должна уметь работать не только с тренировочными уже знакомыми данными, но и с данными которые она никогда не видела. Это очень важно, потому могут быть какие-нибудь данные, которые обладают пока еще не известными скрытыми закономерностями.
	- **Эффективность**. Модель должна уметь работать с очень небольшим количеством промаркированных данных и экстраполировать результаты на огромное число не помеченных данных. Т.к. общее число данных очень высокое, а количество хорошо изученных данных пренебрежимо мало, такое требование является не только логичным, но и необходимым.
- Рассмотрим различные методы и то, как они соотносятся с требованиями, которые астрофизика выдвигает к ним.
- ## Классическое машинное обучение
	- Одним из самых ранних и распространенных моделей машинного обучения является линейная регрессия. Эта модель отлично масштабируется и способна учиться на небольшом количестве данных, но дает сбой если у данных сложная нелинейная закономерность.
	- Гауссовы процессы (Gassuan Processes) хорошо работают с нелинейными данными, но из-за высоких требований к вычислительным мощностям неспособны работать с большими данными.
	- Random Forest имеет хороший баланс между вычислительной эффективностью и экспрессивностью, но его структура сильно ограничивает предсказания по средним весам тренировочных данных, что уменьшает обобщаемость моделей.
	- Отсюда мы можем сделать вывод, что классические модели не удовлетворяют нашим требованиям.
- ##
-