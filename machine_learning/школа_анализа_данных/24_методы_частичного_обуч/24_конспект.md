# Методы частичного обучения (semi-supervised learning)

Этот метод занимает промежуточное состояние между кластеризацией и классификацией. 

Когда у нас есть объекты X и ответы Y --- это supervised learning (обучение с учителем). Самые распространенные --- это методы классификации и регрессии. 
Когда у нас есть только объекты X --- это unsupervised learning (обучение без учителя). Самые распространенные --- это методы класстеризации, поиск аномалий, нейросети и поиск латентных моделей. 

# постановка задачи

Дано:
множество объектов X, множество классов Y;

$$X^l = \{ x_1,..., x_l\}$$ --- размеченная выборка (labeled data);
$$\{y_1,...,y_l\}$$. *Мы можем построить алгоритм классификации и быть готовыми, любой новый объект классифицировать. Не обязательно тот, который не размеченный (находится в неразмеченной выборке), а вообще любой*
$$X^k={x_{l+1},...,x_{l+k}}$$ --- неразмеченная выборка (unlabeled data). 

**Два варианта постановки задачи:**

* Частичное обучение (semi-supervised learning): построить алгоритм классификации a:X $$\rightarrow$$Y.
* Трансдуктивное обучение (transductive learning): зная **все** $$\{ x_{l+1},...,x_{l+k}\}$$, получить метки $$\{y_{l+1},...,y_{l+k} \}$$. *Надо получить метки только для неразмеченных объектах. Мы  считаем, что ничего кроме них нет, и больше не будет.*

Типичные приложения:
классификация и каталогизация текстов, изображений, и т.п.

Математически кажется, что оба подхода одинаковы. В обоих случаю есть выборка объектов, и надо найти к ним ответы. Но, при реализации, методы отличаются друг от друга. 
Самое важное здесь то, что мы должны воспользоваться внутренней кластерной системой неразмеченных данных, для того, чтобы точнее классифицировать. Специфика данной задачи в том, что размеченных данных намного меньше неразмеченной. 

Содержание: методы кластеризации с частичным обучением

* 1) Простые эвристические методы. Особенности задачи SSL. Метод self-training. Композиции алгоритмов классификации. 
* 2) Модификации методов кластеризации. Оптимизационный подход. Кластеризация с ограничениями. 
* 3) Модификации методов классификации. Трансдуктивный SVM. Логистическая регрессия. Expectation Regularization. 

Сначала, познакомимся с простейшими примерами, которые приходят в голову. Затем, посмотрим, как приспособить к методу частичного обучения методы кластеризации --- что делается очень просто. И наконец, посмотрим, как методы классификации приспосабливаются --- в этом случае, сложнее. 

Представим, что у нас есть задача классификации --- две плотности. Но из них нам дали крайне мало точек (размеченых точек, крайне мало) --- дали 5 представителей в одном классе и в другом.  (см SSL_classif). Видя рисунок, можно утверждать, что используя метод кластеризации, мы бы получили более правильные распределения. Отсюда вывод --- надо сначала сделать кластеризацию, а потом по размеченным точкам сделать вывод, где какой класс. 

Если у нас есть какой-то классификационный метод, который способен обучаться по размеченной выборке. Пусть мы используем метод ближайших соседей, и посмотрим, с какой надежностью этот метод относит объекты к [двум] классам. Затем, точки которые с большой надежностью относятся к классам мы добавим в нашу выборку и получим расширенную версию, по которой снова сделаем классификацию. В идеале, два банана должны будут покраситься как и задумано. 

Пусть $$\mu:X^l\rightarrow a$$ --- произвольный метод обучения; классификаторы имеют вид a(x) = $$arg max_{y \in Y}\Gamma_y(x)$$;

"Отступ" объекта --- степень уверенности классификации $$a_i=a(x_i)$$:

$$M_i(a) = \Gamma_{a_i}(x_i) - max_{y\in Y/a_i}\Gamma_y(x_i)$$

 Алгоритм self-training --- обёртка (wrapper) над методом $$\mu$$:
 
 1. Z:=$$X^l$$;
 2. **пока** |Z|<l+k
 3. a:=$$\mu(Z)$$;
 4. $$\Delta$$:=$$\{ x_i\in X^k/Z| M_i(a)\geq M_o\}$$;
 5. $$y_i:=a(x_i)$$ для всех $$x_i\in \Delta$$;
 6. $$Z := Z \cup \Delta$$

$$M_0$$ можно определять, например, из условия $$|\Delta|$$ = 0.05 k

Метод co-training --- это когда два разных метода обучают друг друга. Методы разные, например, решающее дерево и линейный классификатор, либо давать им разные выборки для обучения. 

Пусть $$\mu_1: X^l\rightarrow a_1, \mu_2: X^l \rightarrow a_2$$ --- два существенно различных метода обучения, использующих
--- либо разные наборы признаков;
--- либо разные парадигмы обучения (inductive bias);
--- либо разные источники данных $$X^{l_1}_1, X^{l_2}_2$$

Обучаем один алгоритм, с его помощью классифицируем объекты, доразмечаем их и на этой доразмеченной выборке дообучаем второй алгоритм. Так, по очереди обучает два наших алгоритма. 

Следующий метод co-learning (deSa, 1993)

По сути, является первым методом, но вместо одного алгоритма, мы будем использовать целую группу алгоритмов. В результате мы получим композицию, и будем размечать объекты простым голосованием

Пусть $$\mu_1: X^l\rightarrow a_t$$ --- разные методы обучения, t=1,...,T

**Алгоритм co-learning** --- это self-training для композиции --- простого голосования базовых алгоритмов $$a_1,...,a_T$$:

$$a(x)=argmax_{y\in Y}\Gamma_y(x)$$, $$\Gamma_y(x_i) = \sum^{T}_{t=1}[a_t(x_i)=y]$$

тогда $$M_i(a)$$ --- степень уверенности классификации $$a(x_i)$$


16:47


