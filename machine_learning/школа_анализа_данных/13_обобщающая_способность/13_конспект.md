# лекция №13: Обобщающая способность. Методы отбора признаков

Давайте рассмотрим следующую задачу. Пусть у нас есть обучающая выборка - это множество пар объекты-признаки. Т.е. у нас есть объект и у нас есть ответ, который относит объект к тому или иному классу. 

**Задача**. Найти функцию a(x), способную давать правильные ответы на *тестовых объектах*. 

**Типы признаков:**
* $$D_{j}$$={0,1} - бинарный признак. *Признак да или нет, болел не болел и т.д.*;
* |$$D_{j}$$| < $$\infty$$- номинальный (или категориальный) - *это когда объект принадлежит какому то региону, территории или зоне*.
* $$D_{j}$$ упорядочено - порядковый признак;
* $$D_{j}$$ = R - количественный признак. 
 
**Типы задач, в зависимости от Y:**
* Y= {0,1} или Y = {-1,+1} - классификация на 2 класса;
* Y = {1,...,M} - на М непересекающихся классов. *Если классов много*
* Y = $$\{0,1\}^{M}$$ - на М классов, которые могут пересекаться; *т.е. один и тот же признак может относиться к нескольким классам*
* Y = R - задача восстановления регрессии;
* Y упорядоченно - задача ранжирования (learning to rank)

## Обучение регрессии

Задача регрессии, Y = R

1) Выбираем *модель регрессии*, например, *линейную*:
   $$a(x,w) = <x,w> = \sum^{n}_{j=1}f_{j}(x)w_{j}$$  x, w $$\in R^{n}$$
   *обычно используют скалярное произведение весов и объектов*
2) Выбираем функцию потерь (например, квадратичную):
   $$L(a,y) = (a-y)^{2}$$
3) Минимизируем потери методом наименьших квадратов:
   $$Q(w)= \frac{1}{l}\sum^{l}_{i=1}(a(x_{i},w)-y)^{2}\rightarrow min_{w}$$
   Рассматриваем среднюю ошибку, и минимизируем его по w. Т.е. подбираем такой w, при котором Q(w) - минимально. 
4) Проверяем прогностическую (обобщающую) способность:
   $$\tilde{Q}(w)= \frac{1}{k}\sum^{k}_{i=1}(a(\tilde{x_{i}},w)-\tilde{y}_{i})^{2}$$
   Этот шаг использует полученные значения весов w, и проверяет на тестовой выборке. 
   
## Обучение классификация

Задача классификации Y = {-1;+1}
1) Выбираем модель классификации, например, линейную:
a(x,w) = sign(x,w)
Для классификации можно разные модели, но мы рассмотрим самую простую - линейную. Здесь, так же, рассматривается скалярное произведение, но не значение а знак. Если скалярное произведение меньше 0, то это -1, а если больше 0 то +1. 
2) Выбираем функцию потерь (бинарную или ее аппроксимацию):
L(a,y)=[<$$x_{i}$$,w>$$y_{i}$$<0] $$\leq L(<x_{i},w>y_{i})$$
для оценки потерь, мы используем простой метод, если произведение ниже 0 (т.е. модель оценила неправильно), то мы штрафуем, если больше, то правильно (если оба + или - мы все равно получим >0 положительное значение) и мы не штрафуем. 
То что написано в квадратной скобке - это скобка Айверсона, которая утверждает: если то, что приведено внутри скобки истинно, то это 1, если ложно то 0. 

3) Минимизируем частоту ошибок на обучающей выборке:
$$Q(w)=\frac{1}{l}\sum^{l}_{i=1}[a(x_{i}, w)y_{i}<0]\leq \frac{1}{l}\sum^{l}_{i=1}L(<x_{i},w>y_{i})\rightarrow min$$
т.к. сложно минимизировать ошибки, мы будем смотреть по верхней оценке и считать, что если верхняя оценка будет небольшой, то и частота ошибок будет небольшой. 

4) Проверяем прогностическую (обобщающую) способность
$$\tilde{Q}(w)=\frac{1}{k}\sum^{k}_{i=1}[<\tilde{x_{i}},w>\tilde{y_{i}}<0]$$


## Задача выбора алгоритмов. 

Выбор моделей. Выбор параметров, выбор семейства алгоритмов. Также, к выбору моделей относится и выбор признаков.

Основной вопрос, как померить качество алгоритма? Как понять что лучше? И что такое лучше вообще?

Как лучше оценить качество обучения по прецедентам?

L(a,x) - функция потерь алгоритма a на объекте х
Q(a, $$X^{l}$$) = $$\frac{1}{l}\sum^{l}_{i=1}L(a,x)$$ - функционал качества а на $$X^{l}$$

Оценить качество, можно двумя критериями. Внутренним и внешним. Внутренний, это если мы проверим качество на выборке обучения $$X^{l}$$. 
$$Q_{\mu}(X^{l})=Q(\mu(X^{l}), X^{l})$$
Основной недостаток в том, что мы обучали алгоритм на этой же выборке, поэтому и ошибки будут минимальны. Более того результат будет смещенным, а модель переобучена. 

Второй критерий - это внешний. Когда для проверки качества мы используем ранее отложенную выборку контроля $$X^{k}$$:
$$Q_{\mu}(X^{l},X^{k})=Q(\mu(X^{l}), X^{k})$$
Недостатком является то, что данный результат будет зависеть от разбиения выборки на обучающую и контрольную. 

Еще один метод контроля - это скользящий контроль (cross-validation, CV)
Оценка полного скользящего контроля (complete CV) - усреднение hold-out по всем $$C^{l}_{L}$$ разбиениям $$X^{L}=X^{l}\cup X^{k}$$:

$$CCV(\mu, X^{L}) = \frac{1}{C^{l}_{L}}\sum_{X^{l}\subset X^{L}}Q_{\mu}(X^{l},X^{k})=EQ_{\mu}(X^{l},X^{k})$$

если полагать, что все разбиения равновероятны.

Недостаток 1: эта оценка вычислительно слишком сложна. Устраняется либо аналитическим оцениванием, либо эмпирическим оцениванием по подмножеству разбиений.

Недостаток 2: Эта оценка не учитывает дисперсию hold-out (какое-то одно значение может иметь слишком большую дисперсию, в следствии чего, общее среднее увеличится): устраняется оцениванием распределения значений hold-out

## Эмпирические оценки скользящего контроля 
Контроль по отдельным объектам (leave one out CV), k=1
$$LOO(\mu, X^{L})=\frac{1}{L}\sum^{L}_{i=1}Q_{\mu}(X^{L} \backslash \{x_{i}\}, \{x_{i}\})$$
Алгоритм LOO заключается в следущем: мы убираем 1 значение из обучающей выборки и обучаем без него. А потом проверяем качество модели на этом убранном значении. Потом берем следующее значение, убираем его и обучаем модель без него. Таким образом, мы проходим по всем значениям выборки. Затем, мы берем среднее из ошибок. 

**Недостатки:** ресурсоёмкость, высокая дисперсия. 

Контроль по q-блокам (q-fold CV): случайное разбиение выборки $$X^{L}$$ на q блоков (почти) равной длины. Идея такая же, как и в алгоритме LOO, но в этот раз мы выкидываем блоки и обучаем нашу модель без нее. 

**Недостатки** q-fold CV:
* оценка существенно зависит от разбиения на блоки;
* каждый объект лишь один раз участвует в контроле. 

**Контроль t раз по q блокам** (txq-fold CV) - стандарт "де факто" для тестирования методов обучения. 
*Как осуществлять txq-fold CV?* - алгоритм заключается в том, чтобы разбить блоки по q, t раз, т.е. каждый раз количество q блоков, соответственно и размеры, будут отличаться. И каждый раз мы оцениваем качество нашей модели. 

Выборка $$X^{L}$$ разбивается t раз случайным образом на q блоков.
Качество оценивается по следующей формуле:
$$\tilde{CV}_{txq(\mu, X^{L})}=\frac{1}{t}\sum^{t}_{s=1}\frac{1}{q}\sum^{q}_{n=1}Q_{\mu}(X^{L}\backslash X^{ln}_{sn}, X^{ln}_{sn})$$

**Преимущества** txq-fold CV:
* увеличением t можно улучшать точность оценки (компромисс между точностью и временем вычислений)
* каждый объект участвует в контроле ровно t раз
* можно вычислять доверительные интервалы (при $$t\geq$$ 20)

## Критерий непротиворечивости моделей. 

Идея состоит вот в чем, если наша модель верна, то алгоритмы настроенные по разным частям выборки будут примерно одинаковы
Для примера мы можем взять q-разбиение и применить к первой половине выборки. А для второй половины выборки применить txq разбиение. И сравнить их результаты.

**Недостатки:**
* длина обучения сокращается в 2 раза;
* трудоймкость возрастает в 2 раза. 

## Критерии регуляризации

Основная идея критерий заключается в том, что мы штрафуем сильно за сложные модели, а за простые штрафуем слабо. Потому что сложные модели лучше описывают зависимость, из-за чего могут переобучиться. Простые модели описывают зависимость приближенно, из-за чего вероятность переобучиться будет ниже, но у них может появиться сильно смещение (bias) если мы будем сильно штрафовать простую модель. 
* Сложная модель - сильный штраф;
* Простая модель - слабый штраф.

## Поиск в глубину (DFS, метод ветвей и границ)

Идея заключается в том, чтобы построить дерево признаков (см. рис) ветви которого строятся по принципу первого признака, и по принципу перспектиновтси. Если ветвь (набор признаков) бесперпективны, то мы перестаем его наращивать. 

Пусть J - это текущий набор, а $$Q_{j}^{*}$$ - это лучший набор (набор, который максимально улучшает нашу модель) на данный момент. 

Оценка бесперктивности набора признаков J, набор J не наращивается, если 
Q(J) $$\geq$$ $$\kappa Q_{j}^{*}$$ и J $$\geq j+d$$

d $$\geq$$0 - целочисленный параметр. *Сколько параметров нам надо, прежде чем мы начнем оценивать его перспективность*
$$\kappa \geq$$1 - вещественный параметр. *Во сколько раз признак J может быть хуже, чем лучший набор*. 

Чем меньше d и $$\kappa$$, тем сильнее сокращается перебор. 

## Поиск в ширину (BFS)

Он же многорядный итерационный алгоритм МГУА (МГУА-метод группового учёта аргумента) 

Философский принцип неокончательных решений Габора:
принимая решения, следует оставлять максимальную свободу выбора для принятия последующих решений. 

Для примера рассмотрим жадный метод Add. 
На каждоый j-й итерации мы будем строить не один набор, а множество наборов (скажем топ 5 наборов), называемое j-м рядом. 

**Недостатки:**
* **Трудоемкость**
* **Проблема дубликатов**
  со временем могут появиться дубликаты, поэтому используют проверку на совпадения для исключаения дубликатов. 
* **Адаптивный отбор признаков:**
  на последних шагах, мы можем ввести критерий информативности. Т.е. добавлять только те признаки, которые улучшают нашу модель на I. 

## Генетический алгоритм поиска (идея и терминология)

$$J \subseteq F$$ - индивид (в МГУА "модель"). **Индивид** это подмножество признаков. 
R=$$\{ J^{1}_{t},...,J^{B_{t}}_{t}\}$$ - поколение (в МГУА - "ряд") - набор признаков - это **поколение**
всего у нас признаков n, значит подмножество признаков можем его охарактеризовать бинарным вектором длины n, у которого 1 стоят в тех признаках, которые есть у данного подмножества, а 0 там где их нет. Такой бинарный вектор называется хромосомой.
$$\beta =(\beta_{j})^{n}_{j=1}, \beta_{j}=[f_{j}\in J]$$ = хромосома кодирующая J; 

Бинарная операция скрещивания $$\beta=\beta' \times \beta''$$
$$\beta_{j}=\left\{\begin{aligned}\beta'_{j},\text{с вероятностью 1/2;}\\
\beta''_{j},\text{с вероятностью 1/2}.\\\end{aligned}\right.$$

Унарная операция мутации $$\beta=\sim\beta'$$

$$\beta_{j}=\left\{\begin{aligned}1-\beta'_{j},\text{с вероятностью } p_{m}\text{;}\\
\beta'_{j},\text{с вероятностью }1 - p_{m}.\\\end{aligned}\right.$$
где параметр $$p_m$$ - **вероятность мутации**

## Генетический алгоритм
см рисунок. 
На входе мы задаем d (сколько итераций мы можем не улучшать качество) и $$p_m$$ (вероятность мутаций). B - размер популяций, Т - число поколений (итераций, в генетическом алгоритме итерации называются поколениями).

Инициализируем случайную популяцию B. 
Все индивиды мы сортируем по нашему критерию качества. 
Оставляем только B лучших - это называется селекция, т.е. выживают сильнейшие, те у которых качество было хуже - те умерли. 
Если у текущей популяции качество лучше, чем у известного самого лучшего, то мы его запоминаем. 
если уже d поколений мы не улучшаем качество, то завершаем алгоритм. 
В противном случае, мы порождаем следующее поколение. 
Мы скрещиваем все существующие пары, а их потомков еще и мутируем. И добавляем к следующей итерации и тех, кто был на текущей.  

# Эвристики для управления процессов эволюции
* Увеличивать вероятности перехода признаков от более успешноо родителя к потомку.
* Накапливать оценки информативности признаков. Чем более информативен признак, тем выше вероятность его включения в набор во время мутации.
* Применение совокупности критериев качества.
* Скрещивать только лучшие индивиды (элитаризм)
* Переносить лучшие индивиды в следующее поколение
* В случае стагнации увеличивать вероятность мутаций
* Параллельно выращивается несколько изолированных популяций (островная модель эволюции)

**Преимущества:**
* it is fun!
* возможность введения различных эвристик;
* решает задачи даже с очень большим числом признаков

**Недостатки:**
* относительно медленная сходимость;
* отсутствие теории;
* подбор параметров - непростое искусство. 








