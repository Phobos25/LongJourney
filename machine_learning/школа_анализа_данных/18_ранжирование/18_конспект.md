# Методы обучения ранжированию. (Learning to rank)

Ранжирование отличается от классификации и регрессии тем, что у него не заданы классы на парах объект ответ, а задан некий порядок. 

X --- множество объектов;
$$X^l$$ = {$$x_1,...,x_l$$} --- обучающая выборка
$$i \prec j$$ --- правильный порядок на параха (i,j) $$\in$$ $$\{1,...,l\}^2$$
это означает, что j лучше чем i. 
Задача
построить ранжирующую функцию a: $$X\rightarrow R$$такую, что 
$$i\prec j \Rightarrow a(x_i)<a(x_j)$$

Линейная модель ранжирования:
$$a(x;w) = <x,w>$$
где x $$\rightarrow (f_1(x),...,f_n(x))\in R^n$$  --- вектор признаков объекта x

Используется в текстовых документах, в текстовых поисках. 

**Пример 1**
Если у нас есть поиск каких-то документов, после того, как мы их нашли, по тем или иным признакам.Т.к. их количество может быть очень большим, и выдавать не отсортированный список будет не очень эффективно, мы должны данный список отсортировать по степени релевантности. После этого и выдать список тому, кто искал. В данной задаче, ранжирование заключается в том, чтобы отсортировать объекты по степени релевантности. 

Релевантность отмечается специальными людьми-ассессорами. 

Типы признаков:
* функции только документа d
* функции только запроса q
* функции запроса и документа (q,d)
Разумнее всего использовать именно пыра запрос-документ (q,d). В таком случае, мы можем использовать текстовые признаки: встречаются ли слова запроса в документе или в заголовке. Или встречаются не сами слова, а их синонимы. Можно придумать очень много признаков
* текстовые
    - слова запроса q встречаются в d чаще обычного
    - слова запроса q есть в заголовках или выделены в d
* ссылочные
    - на документ d много ссылаются
    - документ d содержит много полезных ссылок

Можно еще оценить насколько хорош документ, т.е. на сколько часто на него ссылаются. Или как много полезных ссылок в документе. 

* кликовые 
    - на документ d часто кликают
    - на документ d часто кликают по запросу q

Или, насколько часто кликают на данный документ. Или даже, пара запрос-документ (q,d). 

В Яндексе придумали около 1000 признаков (в их поисковой системе) за 5 лет. 

# TF-IDF(q,d) --- мера релевантности документа d запросу q

$$n_{dw}$$ (term frequency)  --- число вхождений слова w в тексте d;
$$N_w$$ (document frequency) --- число документов, содержащих w;
N --- число документов в коллекции D;

$$N_w/N$$ --- число вероятности встретить слово w в документе;
$$(N_w/N)^{n_{dw}}$$ --- оценка вероятности встретить его в $$n_{dw}$$ раз;

$$P(q,d) = \prod_{w\in q}(N_w/N)^{n_{dw}}$$ --- оценка вероятности встретить в документе d слова запроса q = {$$w_1,...,w_k$$} чисто случайно;
Оценка релевантности запроса q документу d:
$$-logP(q,d) = \sum_{w\in q}\underbrace{n_{dw}}_\text{TF(w,d)}\underbrace{long(N/N_w)}_\text{IDF(w)}\rightarrow max$$

TF(w,d) = $$n_{dw}$$ --- term frequency
IDF(w) = long(N/$$N_w$$) --- inverted document frequency

Для понимания формулы релевантности рассмотрим следующее: множество документов это есть пространство вероятностей, а попадание слова в один из документов это вероятность. Если мы все слова из документа разложим в один длинный текст, это тоже будет пространство вероятностей, а слово в этом тексте это вероятность. Для первого оценка вероятности будет равна $$N_w/N$$. Для второго случая --- в пространстве длинного текста это $$(N_w/N)^{n_{dw}}$$. Тогда мы можем оценить вероятность встретить запрос в документе:
$$P(q,d) = \prod_{w\in q}(N_w/N)^{n_{dw}}$$. Здесь, если $$N_w/N$$ маленькое, а встречается в документе часто, то это слово будет иметь высокую релевантность. Чем ниже вероятность встретить в документе, т.е. чем ниже значение P(q,d) тем выше релевантность. 
Знак минус в формуле, потому чем ниже вероятность тем выше релевантность. 

# PageRank --- классический ссылочный признак
Данный метод был впервые предложен Сергеем Брином и Лоуренсем Пейджом в 1998 г. [Sergey Brin, Lawrence Page. The anatomy of a Large-Scale Hypertextual Web Search Engine, 1998]

Документ d тем важнее,
- чем больше других документов c ссылаются на d,
- чем важнее документы c, ссылающиеся на d,
- чем меньше других ссылок имеют эти документы c.

Вероятность попасть на страницу d, если кликать случайно:

$$PR(d) = \frac{1-\sigma}{N} + \sigma\sum_{c\in D^{in}_{d}}\frac{PR(c)}{|D^{out}_{c}|}$$

$$D^{in}_{d}\subset D$$ --- множество дкоументов, ссылающихся на d,
$$D^{out}_{c}\subset D$$ --- множество документов, на которые ссылается c, 
$$\sigma = 0.85$$ --- вероятность продолжать клики (damping factor)
N --- число документов в коллекции D

Этот алгоритм не совсем тот, который используется в гугле. Здесь вопрос того, как долго искать эти документы остается открытым. Это классический случай, когда реальный алгоритм скрывается, а публике открывается упрощенная модель. 

22:51
