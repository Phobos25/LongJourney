# Методы обучения ранжированию. (Learning to rank)

Ранжирование отличается от классификации и регрессии тем, что у него не заданы классы на парах объект ответ, а задан некий порядок. 

X --- множество объектов;
$$X^l$$ = {$$x_1,...,x_l$$} --- обучающая выборка
$$i \prec j$$ --- правильный порядок на параха (i,j) $$\in$$ $$\{1,...,l\}^2$$
это означает, что j лучше чем i. 
Задача
построить ранжирующую функцию a: $$X\rightarrow R$$такую, что 
$$i\prec j \Rightarrow a(x_i)<a(x_j)$$

Линейная модель ранжирования:
$$a(x;w) = <x,w>$$
где x $$\rightarrow (f_1(x),...,f_n(x))\in R^n$$  --- вектор признаков объекта x

Используется в текстовых документах, в текстовых поисках. 

**Пример 1**
Если у нас есть поиск каких-то документов, после того, как мы их нашли, по тем или иным признакам.Т.к. их количество может быть очень большим, и выдавать не отсортированный список будет не очень эффективно, мы должны данный список отсортировать по степени релевантности. После этого и выдать список тому, кто искал. В данной задаче, ранжирование заключается в том, чтобы отсортировать объекты по степени релевантности. 

Релевантность отмечается специальными людьми-ассессорами. 

Типы признаков:
* функции только документа d
* функции только запроса q
* функции запроса и документа (q,d)
Разумнее всего использовать именно пыра запрос-документ (q,d). В таком случае, мы можем использовать текстовые признаки: встречаются ли слова запроса в документе или в заголовке. Или встречаются не сами слова, а их синонимы. Можно придумать очень много признаков
* текстовые
    - слова запроса q встречаются в d чаще обычного
    - слова запроса q есть в заголовках или выделены в d
* ссылочные
    - на документ d много ссылаются
    - документ d содержит много полезных ссылок

Можно еще оценить насколько хорош документ, т.е. на сколько часто на него ссылаются. Или как много полезных ссылок в документе. 

* кликовые 
    - на документ d часто кликают
    - на документ d часто кликают по запросу q

Или, насколько часто кликают на данный документ. Или даже, пара запрос-документ (q,d). 

В Яндексе придумали около 1000 признаков (в их поисковой системе) за 5 лет. 

# TF-IDF(q,d) --- мера релевантности документа d запросу q

$$n_{dw}$$ (term frequency)  --- число вхождений слова w в тексте d;
$$N_w$$ (document frequency) --- число документов, содержащих w;
N --- число документов в коллекции D;

$$N_w/N$$ --- число вероятности встретить слово w в документе;
$$(N_w/N)^{n_{dw}}$$ --- оценка вероятности встретить его в $$n_{dw}$$ раз;

$$P(q,d) = \prod_{w\in q}(N_w/N)^{n_{dw}}$$ --- оценка вероятности встретить в документе d слова запроса q = {$$w_1,...,w_k$$} чисто случайно;
Оценка релевантности запроса q документу d:
$$-logP(q,d) = \sum_{w\in q}\underbrace{n_{dw}}_\text{TF(w,d)}\underbrace{long(N/N_w)}_\text{IDF(w)}\rightarrow max$$

TF(w,d) = $$n_{dw}$$ --- term frequency
IDF(w) = long(N/$$N_w$$) --- inverted document frequency

Для понимания формулы релевантности рассмотрим следующее: множество документов это есть пространство вероятностей, а попадание слова в один из документов это вероятность. Если мы все слова из документа разложим в один длинный текст, это тоже будет пространство вероятностей, а слово в этом тексте это вероятность. Для первого оценка вероятности будет равна $$N_w/N$$. Для второго случая --- в пространстве длинного текста это $$(N_w/N)^{n_{dw}}$$. Тогда мы можем оценить вероятность встретить запрос в документе:
$$P(q,d) = \prod_{w\in q}(N_w/N)^{n_{dw}}$$. Здесь, если $$N_w/N$$ маленькое, а встречается в документе часто, то это слово будет иметь высокую релевантность. Чем ниже вероятность встретить в документе, т.е. чем ниже значение P(q,d) тем выше релевантность. 
Знак минус в формуле, потому чем ниже вероятность тем выше релевантность. 

# PageRank --- классический ссылочный признак
Данный метод был впервые предложен Сергеем Брином и Лоуренсем Пейджом в 1998 г. [Sergey Brin, Lawrence Page. The anatomy of a Large-Scale Hypertextual Web Search Engine, 1998]

Документ d тем важнее,
- чем больше других документов c ссылаются на d,
- чем важнее документы c, ссылающиеся на d,
- чем меньше других ссылок имеют эти документы c.

Вероятность попасть на страницу d, если кликать случайно:

$$PR(d) = \frac{1-\sigma}{N} + \sigma\sum_{c\in D^{in}_{d}}\frac{PR(c)}{|D^{out}_{c}|}$$

$$D^{in}_{d}\subset D$$ --- множество дкоументов, ссылающихся на d,
$$D^{out}_{c}\subset D$$ --- множество документов, на которые ссылается c, 
$$\sigma = 0.85$$ --- вероятность продолжать клики (damping factor)
N --- число документов в коллекции D

Этот алгоритм не совсем тот, который используется в гугле. Здесь вопрос того, как долго искать эти документы остается открытым. Это классический случай, когда реальный алгоритм скрывается, а публике открывается упрощенная модель. 


# ранжирование в интернет магазине

Данная задача заключается в том, чтобы создать рекоммендательную систему. Достаточно сильную, чтобы не пришлось ее корректировать. Данные для такой задачи выглядят как пары юзер-фильм. И для нового юзера первым делом
ищется похожий юзер (эталонный юзер), если мы такого найдем, мы будем ему рекоммендовать те же фильмы, что и эталонному юзеру. Благодаря чему, рекоммендации новому юзеру будут такие же точные, как и 
для юзера с большим стажем. (прим. похожую систему можно было бы использовать в dating apps, но видимо они там используют какую-то другую систему намного хуже). 
# Доля "Дефектных пар"
Пусть Y $$\subseteq$$ R, y(q,d) --- релевантность,
a(q,d) --- искомая функция ранжирования, 
$$d^{(i)}_{q}$$ --- i-й документ по убыванию a(q,d)
Доля инверсий порядка среди первых n документов:

$$DP_n(q) = \frac{2}{n(n-1)}\sum^{n}_{i<j}[y(q,d_q^{i})<y(q,d^{(i)}_{q})]$$

Связь с коэффициентом ранговой корреляции ($$\tau$$ Керделла):
$$\tau(a,y) = 1 - 2\cdot DP_n(q)$$

Связь с AUC (area under ROC-curve) в задачах классификации с двумя классами Y = {-1,+1}, a: X $$\rightarrow$$ Y

$$AUC_n(q) = \frac{1}{l_-l_+}\sum^{n}_{i,j=1} [y_i>y_j][a(x_i)<a(x_j)]=\frac{n(n-1)}{2l_-l_+}\cdot DP_n(q)$$
AUC является мерой оценки качества ранжирования. Идеальное ранжирование, это когда 0 и 1 идеально отсортированы, сначала 0 а потом 1, и очень легко увидеть, где надо поставить разделяющую кривую. 

Задача ранжирования усложняется тем, что мера оценки качества сильно зависит от типа поставленной задачи. Где-то достаточно оценить min average precision или даже просто average precision при заданном n, а где-то оценка дается пользователем, насколько он удовлетворен. 

И данный метод DCG --- Discounted Cumulative Gain

Пусть $$Y \subseteq R$$, y(q,d) --- релевантность. 
a(q,d) --- искомая функция ранжирования, 
$$d^{(i)}_{q}$$ --- i-й документ по убыванию a(q,d). 

Дисконтированная (взвешенная) сумма выигрышей:

$$DCG_n(q) = \sum^{n}_{i=1}\underbrace{G_q(d^{(i)}_{q})}_\text{gain}\cdot \underbrace{D(i)}_\text{discount}$$

$$G_q(d) = (2^{y(q,d)}-1)$$ --- больший вес релевантным документам
$$D(i) = 1/\log_2{(i+1)}$$ --- больший вес в начале выдачи 

Нормированная дисконтированная сумма выигрышей:

$$NDCG_n(q)=\frac{DCG_n(q)}{maxDCG_n(q)}$$

$$maxDCG_n(q)$$ --- это $$DCG_n(q)$$ при идеальном ранжировании 

Пусть у нас ассессоры снова задают вещественные оценки релевантности. Основная идея заключается в том, чтобы дать больший вес релеватным документам и дать больший вес документам в начале выдачи. Т.е. если релевантность убывает в ранжированном ряду $$d^{(i)}_{q}$$, то это идеальный вариант. 

максимальное значение $$DCG_n(q)$$ подсчитать легко, если вместо функции ранжирования a(q,d) взять y(q,d), то это нам даст максимальную сумму выигрышей. 
# Яндекс pFound --- модель поведения пользователя

Пусть $$Y\subseteq [0,1]$$,
y(q,d) --- релевантность, оценка вероятности найти ответ в d,
a(q,d) --- искомая функция ранжирования,
$$d^{(i)}_{q}$$ --- i-й документ по убывания a(q,d)

Вероятность найти ответ в первых n документах:

$$pFound_n(q)=\sum^{n}_{i=1}P_i\cdot y(q,d^{(i)}_{q})$$,

где $$P_i$$ --- вероятность дойти до i-го документа
$$P_i=1$$ --- мы берем его за единицу, т.е. вероятность максимальна.
$$P_{i+1}=P_i \cdot(1-y(q,d^{(1)}_{q}))\cdot(1-P_{out})$$

$$P_{i+1}$$$ --- вероятность дойти до следующего документа.
$$P_{out}$$ --- вероятность прекратить поиск без ответа.
$$(1-y(q,d^{(1)}_{q}))$$ --- вероятность найти искомый ответ в документе. 

т.к. оценить вероятность найти ответ в документе в численной форме нереально. Ассессор пользуется ранговой шкалой (см. рис)
Числа берутся из кликов пользователей по документам, которые были оценены ассессорами. Грубая оценка, но если база кликов очень большая, то можно получить более-менее точную оценку. 

# Основные подходы к ранжировнаию

* Point-wise --- поточечный. *Пытается приспособить уже известные классификационные и регрессионные методы к текущей выборке.*
* Pair-wise --- попарный. *Использование пар объект-документ. Это значит, что и функционал нашей модели должен строиться по тому же принципу.*
* List-wise --- списочный. *Сразу рассматривается весь список, и пытаемся оптимизировать этот список. Самый сложный и в литературе, часто упоминается, как самый эффективный и правильный.*

Следует отметить, что в Яндексе использоуется Pair-wise подход, т.к. он оказался выгодней и эффективней. 

Переход к галдкому функционалу качества ранжирования:

$$Q(a)=\sum_{i\prec j}\underbrace{[a(x_j)-a(x_i)]<0}_\text{Margin(i,j)}\leq\sum_{i\prec j}L(a(x_j)-a(x_i))\rightarrow min$$
Слева стоит число ошибок. *Мы рассматриваем пары объектов i хуже чем j, но если разность их оценки ниже 0, значит это ошибка.*
Справа мы заменяем нашу пороговую модель некой гладкой (непрерывно дифференцируемая функция) не возрастающей функцией L, и получаем оптимизационную задачу, которую мы можем решать. Здесь, для обучения можно использовать SVM, AdaBoost, Logistical Regression и т.д. Эти модели можно приспособить для нашей задачи. 

где a(x) - алгоритм ранжирования
L(x) - убывающая непрерывная функция отступа Margin(i,j)
* $$L(M)=(1-M)_+$$ --- RankSVM
* $$L(M)=\exp(-M)$$ --- RankBoost
* $$L(M)=\log{(1+e^{-M})}$$ --- RankNet

Ordinal Classification SVM

Как мы помним, метод SVM заклчюается в том, чтобы разделить данные одной гиперплоскостью. В случае ранжирования нам надо разделить их на 5 (т.к. рангов релевантности 5) 4-мя гиперплоскостями. Если в SVM мы штрафовали за то, что объект пересекал границу (размер штрафа определялся величиной $$\xi$$), то в этом случаем мы штрафуем объекты если они пересекут границу слева или справа (будет два $$\xi$$). Т.е. у нас неравенство становится двусторонним, в зависимости от того, какой объект приходит на вход. 
Это одна из конструкций для решения задачи ранжирования. Данный метод получился поточечным. 
Следует учитывать, что у краевых случаем будет только 1 граница. 

1:10:40
