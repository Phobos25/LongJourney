# Конспекты курса machine learning

# линейные методы классификации
история открытия обучаемых нейросетей.
В 40-е 50-е гг. прошлого века, нейрофизиологи
проводили множество экспериментов по исследованию
работы нейронов и их обучаемости. Оказывается, большая
часть обучения проходит не в самих нервных клетках а в 
синапсах. Если два нейрона по соседству возбуждаются 
одновременно (т.е. 1 передал другому импульс и угадал),
то у них связь укрепляется. Т.е. при угадывания
нужного импульса клетки награждаются усилением связи с друг другом.

С точки зрения математики это представляет собой оптимизацию
какой-то градиентной функции. 

Что приводит нас к методу градиентного спуска. Метод заключается в том, чтобы
найти для линейной функции активации антиградиент. Градиент - направлен в сторо-
ну максимального возрастания, а антиградиент в сторону максимального убывания.
Поэтому, данный метод относится к методом минимизации. 
w^0 - начальное приближение
w^(t+1) := w^t - eta * grad(Q(w^t)), где grad(Q(w)) = (dQ/dw_j)^n_j =0
eta - градиентный шаг, или темп обучения (learning rate)

w^(t+1) := w^t - eta * sum(L'((w^t,x_i),y_i))x_i * y_i

Ниже приводится псевдокод стохастического градиентного спуска (stochastic Gradient):

Вход:
    выборка X^l; темп обучения eta, параметр lambda;
Выход:
    веса w_0,w_1,...w_n

1: инициализировать веса w_j, j=0,...n
2: инициализировать текущую оценку функционала:
   Q := sum(L((w,x_i)y_i)
3: повторять
4:    выбрать объект x_i из X^l (например, случайно)
5:    вычислить потерю: epsilon_i := L((w,x_i)y1)
6:    градиентный шаг: w:= w - eta * L'((w,x_i)y_i)x_i* y_i;
7:    оценить значения функционала: Q := (1-lambda)Q + lambda* epsilon_i
8: пока значение Q и/или веса w не стабилизируются

# SG: порядок предъявления объектов

Возможны варианты:

1) перетасовка объектов (shuffling):
   попеременно брать объекты из разных классов
2) чаще брать те бъекты, на которых была допущена большая ошибка
  (чем меньше M_i, тем больше вероятность взять объект)
  (чем меньше |M_i|, тем больше вероятность взять объект)
3) вообще не брать "хорошие объекты, у которых M_i > mu. (при этом
немного ускоряется сходимость)

4) вообще не брать объекты-"выбросы" у которых M_i < mu. (при этом
может улучшиться качество классификации)

Параметры mu_+, mu_- придется подбирать
 
**Как выбрать граидентный шаг? (learning rate)**

Множество теорем утверждает, что почти в любом случае гарантируется сходимость.
Несмотря на это, на практике такое не всегда случается. 

Либо использовать метод скорейшего спуска. По формуле, определеить адаптивный шаг

Самый простой, самый надежный, но не всегда самый быстрый, с точки зрения подбора
и подготовки к моделированию - это пробные случайные шаги. 
Пробуем с маленького до больших learning rate. (0.01, 0.03, 0.1, 0.3, etc.)

Строго гвооря, данный метод, метод градиентного спуска эвристический.
 т.е. надо подбирать, подгонять оптимальные параметры. Заранее при помощи формул
нельзя опдобрать необходимые параметры. 

#Проблема переобучения

1) слишком мало объектов, слишком много признаков
2) линейная зависимость (мультиколлинеарность) признака. Напр. есть доход мужа, 
доход жены и семейный доход. 

Для того, чтобы избежать переобучения надо исправлять основные симптомы:
Сокращение весов (w - weight):

вводится коэффициент регулизации lambda
Тогда, получается, что мы штрафуем алгоритм за слишком большой w:
Q_lambda (w;X^l) = Q(w,X^l) + lambda/2 * |w|^2 -> min
Градиент
grad Q_lambda(w) = grad Q(w) + lambda * w

*Распределение Гаусса*
lambda/2 * |w|^2 - эквивалентно предположению о том, что w распределяется
по нормальному (гауссовскому закону)

*Распределеине Лапласа*
Можно использовать и распределение лапласа вместо гаусса.
Разница в том, что гаусс похож на колокол, а лаплас на треугольник с острой вершиной
и хвосты длиннее (sigma, 2sigma и т.п.)

получается: 1/C * sum(|w|)    (на курсере такой исползовали)
где C - гиперпараметр

*Регуляризация в линейных классификатор*

