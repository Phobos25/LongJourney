## 15_лекция. Композиции классификаторов

Идея композиции заключается в том, что если мы хотим поточнее узнать длину палки. Мы должны измерять его несколько раз разными линейками и усреднять их. Даже если линейки не зависимы друг от друга, то дисперсия усреднения будет уменьшаться как корень квадартный от количества измерений ($$\sqrt{N}$$, N - количество измерений). 

В композиционной методике используется несколько алгоритмов для обучения на одной и той же выборке, что исходя из сказанного выше, должна уменьшать среднюю ошибку модели. 

* **Пример 1**: классификация на 2 класса, Y={-1,+1};
    $$a(x)=sign(b(x))$$
где R=R, b:X $$\rightarrow$$ R, c(b)$$\equiv$$sign(b)

* **Пример 2**: классификация на M классов Y = {1,...,M}:
    $$a(x)=argmax_{y\in Y}b_{y}(x)$$
где R=$$R^{M}$$, b: X $$\rightarrow R^{M}$$, C($$b_{1},...,b_{M}$$)$$\equiv argmax_{y\in Y b_{y}}$$

* **Пример 3**: регрессия, Y=R=*R*:
    C(b)$$\equiv$$b - решающее правило не нужно. 

Смесь алгоритмов (Mixture of Experts) - алгоритм заключается в предположении, что в своем подпространстве объектов определенные алгоритмы работают лучше. В своем роде, как эксперт в области своей компетенции. Эта компетенция зависит от X. Вместо весов используется функция, которая зависит от x. 

**Адаптивный буст (AdaBoost)**
Базовый алгоритм возвращает либо +1, либо -1. обобщение - возвращает 0, (лучше промолчать, чем соврать) не дает никакого вклада. 

Мы строим взвешенное голосование и берем его знак. 
$$a(x)=sign(\sum^{T}_{t=1})\alpha_{t}b(t)(x)$$, $$x\in X$$

Наша задача одновременно найти базовые алгоритмы $$b_{t}$$ и коэффициенты к нему $$\alpha_{t}$$. Такая задача очень сложна в исполнении, поэтому мы будем применять жадный алгоритм добавления для упрощения. Мы будем добавлять базовые алгоритмы в композицию по очереди, и каждый следующий должен компенсировать недостатки предыдущего. 

$$Q_{T}=\sum^{l}_{i=1}[y_{i}\sum^{T}_{t=1}\alpha_{i}b_{t}(x_{i})<0]$$

Две основные эвристики бустинга:
* фиксация базовых алгоритмов $$\alpha_{1}b_{1}(x),...,\alpha_{t-1}b_{t-1}(x)$$ при добавлении $$\alpha_{t}b_{t}(x)$$;
* гладкая аппроксимация пороговой функции потерь $$[M\leq 0]$$

**Алгоритм AdaBoost**

**Вход** Обучающая выборка $$X^{l}$$; параметр Т

**Выход** базовые алгоритмы и их веса $$\alpha_{t}b_{t}$$, t=1,...,T;
1) инициализировать веса объектов
$$w_{i}:=1/l, i=1,...,l$$

2) **для всех** t=1,...,T

3) обучить базовый алгоритм;
$$b_{t}:=argmin_{b} N(b;W^{l})$$

4) $$\alpha_{t}:=\frac{1}{2}ln\frac{1-N(b_{t};W^{l})}{N(b_{t};W^{l})}$$

5)  обновить веса объектов
$$w_{i}:=w_{i}exp(- \alpha_{t}y_{i}b_{t}(x_{i}))$$, i=1,...,l;


6) нормировать веса объектов
$$w_{0}:=\sum^{l}_{j=1}w_{j}$$
$$w_{i}:=w_{i}/w_{0}$$, i=1,...,t

AdaBoost имеет один единственный цикл. 
Вначале, мы говорим, что все объекты имеют одинаковые веса. Первйы базовый алгоритм решается так же, как и в обычном машинном обучении. Минимизируя ошибки и т.п. 

Далее, мы рассчитываем коэффициент $$\alpha$$ для нашего базового алгоритма. Затем обновляем веса объектов (шаг 5). Интерпретируется данный шаг довольно просто. Если наш базовый алгоритм ошибается, т.е. $$y_{i}b_{t}(x_{i})$$ будет отрицательным, то выражение под экспонентой будет положительным (мы полагаем, что параметр $$\alpha$$ всегда положителен) и, следовательно, вес следующего алгоритма будет выше. А, если оценка все лучше и лучше, то веса будут становиться все ниже и ниже, т.к. они уже работают и нам не надо на них настраиваться. 

## Эвристики и рекомендации

* Базовые классификаторы (weak classifier):
1) решающие деревья - используются чаще всего;
2) пороговые правила (data stumps), или пни, срубленные деревья: Это означает, что веток нет, есть только один корень, который сравнивается со значением порога:
   $$B = \{ b(x) = [f_{j}(x)>< \theta]|j=1,...,n, \theta \in R\}$$
3) для SVM бустинг не эффективен.

* Отсев шума: отбросить объекты с наибольшими $$w_{i}$$.
* Модификация формулы для $$\alpha_{t}$$ на случай N = 0:
  $$\alpha_{t}:= \frac{1}{2}\ln\frac{1-N(b_{t};W^{l})+\frac{1}{l}}{N(b_{t};W^{l})+\frac{1}{l}}$$
т.е. на случай, если базовый алгоритм не ошибается. Можно это интерпретировать, как то, что другие алгоритмы не нужны, базовый прекрасно справляется. Но, если алгоритм не ошибся на обучающей выборке, то это не значит, что он не ошибется на контрольной выборке. Для этого и используется байесовская частотная оценка. Необходимость в композиции не отпадает, даже если базовый алгоритм дает очень хорошую точность на обучающей выборке. 
* Дополнительный критерий остановки:
  увеличение частоты ошибок на контрольной выборке. На практике, число алгоритмов в композиции выбирается заранее, 300, 3000 или 30, взависимости от задачи. Теория утверждает, что при повышении сложности растет переобучение. Но с композициями такого не случалось, для этого надо было увеличить сложность еще сильнее (на порядок или на два порядка увеличить число T). Что является хорошим качеством, т.к. не надо слишком точно подбирать число T --- число базовых алгоритмов. 

## Обоснование бустинга

Давайте ужесточим поняите ошибки, и будем считать, что ошибка это когда отступ меньше $$\theta$$

$$\nu_{\theta}(a,X^{l})=\frac{1}{l}\sum^{l}_{i=1}[b(x_{i}y_{i})\leq\theta], \theta>0$$
Ошибка это не когда мы пересекли границу двух классов, а ошибка когда мы к ней приблизились на величину $$\theta$$
Обычная частота ошибок $$\nu_{0}(a,X^{l}) \leq \nu_{\theta}(a,X^{l})$$

**Теорема (Freund, Schapire, Bartlett, 1998)**
Если $$|B|<\infty$$, то $$\forall\theta > 0, \forall\eta\in (0,1)$$ с вероятностью $$1-\eta$$
если мы пользуемся не слишком богатым семейством алгоритмов, то справедливо вероятностное неравенство. Вероятность близка к единице (т.к. мы вправе предполагать, что $$\eta$$ будет маленьким $$\sim5\%$$): 

$$P[ya(x)<0]\leq \nu_{\theta}(a,X^{l})+C\sqrt{\frac{ln{|B|}ln{l}}{l\theta^{2}}+\frac{1}{l}\ln{\frac{1}{\eta}}}$$

Слева стоит вероятность ошибки --- отступ для нашей композиции. Верхняя оценка определяется частотой ошибок на нашей выборке, доля объектов с отступом меньше чем $$\theta$$, + штрафное слагаемое. Самое любопытное свойство штрафного слагаемого заклчюается в том, что он не зависит от T --- числа базовых алгоритмов. Но, он зависит от сложности забового семейства алгритмов, что, кстати, оправдывает использование решающих пней и прочих идиотстких конструкций. 

Если рассмотреть другой параметр, от которого зависит неравенство, $$\theta$$, то при его увеличении штрафное слагаемое уменьшается, а частота ошибок увеличивается. Поэтому можно минимизировать данное выражение по $$\theta$$? чтобы получить его оптимальное значение. Для удовлетворения такого условия алгоритм должен увеличивать отступ. Т.е. сделать распределение отступов таким, чтобы для большинства этих объектов отступ становился все больше и больше. Оказывается, в этом и заключаается замечательное свойство бустинга. Он как бы раздвигает классы в  пространстве растущем размерности.  


**Основной вывод:** оценка не зависит от T явно. Голосование не увеличивает сложность, эффективной используемого множества алгоритмов. 


* С ростом T распределение отступов сдвигается вправо, то есть бустинг "раздвигает" классы в пространстве векторов растущей размерности;
* значит, в оценке можно уменьшить второй член, увеличив $$\theta$$ и не изменив $$\nu_{\theta} (a, X^{l})$$;
* Можно уменьшить второй член, если уменьшить |B|, то есть взять простое семейство базовых алгоритмов. 

Основным недостатком AdaBoost является то, что алгоритм слишком жесткий. Слишком жестко наказывает на ошибки и, как следствие, начинает обучаться на ошибках. Если, к примеру, у нас были выбросы, то алгоритм начинается обучаться на них, и мы получим неправильную оценку. 

# Градиентный бустинг для произвольной функции потерь 
Friedman G. Greedy Function Approximation: A gradent boosting machine, 1999. 

Линейная (выпуклая) комбинация базовых алгоирмтов:

$$a(x)=\sum^{T}_{t=1}\alpha_{t}b_{t}(x). x\in X, \alpha_{t}\in R$$

В отличие от AdaBoost, тут нет никаких ограничений у базовых алгоритмов, они могут принимать любое значение, а не только {-1;0;+1}

$$Q(\alpha, b; X^{l})=\sum^{l}_{i=1}L(\underbrace{\underbrace{\sum^{T-1}_{t=1}\alpha_{t}b_{t}}_{\text{$f_{T-1,i}$}}+\alpha b(x_{i}),y_{i}}_\text{$f_{T,i}$})\rightarrow min_{a,b}$$

$$f_{T-1,i}=(f_{T-1,i})^{l}_{i=1}$$ - текущее приближение
$$f_{T,i}=(f_{T,i})^{l}_{i=1}$$ - следующее приближение

**Алгоритм градиентного бустинга (Gradient Boosting)**

**Вход** Обучающая выборка $$X^{l}$$; параметр Т

**Выход** базовые алгоритмы и их веса $$\alpha_{t}b_{t}$$, t=1,...,T;
1) инициализировать веса объектов
$$w_{i}:=1/l, i=1,...,l$$

2) **для всех** t=1,...,T

3) найти базовый алгоритм, приближающий градиент:

    $$b_{t}:=argmin_{b} \sum^{l}_{i=1}(b(x_{i})+L'(f_{i},y_{i}))^{2}$$;

4) решить задачу одномерной минимизации:
    $$\alpha_{t}:=argmin_{\alpha>0}\sum^{l}_{i=1}L(f_{i}+\alpha b_{t}(x_{i},y_{i}))$$;

5)  обновить значения композиции на объектах выборки:
    $$f_{i}:=f_{i}+\alpha_{t}b_{t}(x_{i})$$; i=1,...,t
    
Здесь, L - это любая функция потерь, на усмотрение разработчика. 

## Стохастический градиентный бустинг (SGB):

**Идея**: на шагах 3-5 использовать не всю выборку $$X^{l}$$, а случайную подвыборку без возвращений

**Преимущества:**
* улучшается качество;
* улучшается сходимость;
* уменьшается время обучения. 

## **Резюме:**

* Градиентный бустинг - наиболее общий из всех бустингов:
-- произвольная функция потерь;
-- произвольное пространство оценок R;
-- подходит для регрессии, классификации, ранжирования.

* Стохастический вариант SGB --- лучше и быстрее

* Чаще всего GB применяется к решающим деревьям

* Градиентный бустинг над ODT = Yandex MatrixNet

**Несколько эмпирических наблюдений**
* Веса алгоритмов не столь важный для выравнивания отступов;
* Веса объектов не столь важны для обеспечения различности;
* Не удается строить короткие композиции из "сильных" алгоритмов типа SVM (только длинные из слабых)


1:15:00





