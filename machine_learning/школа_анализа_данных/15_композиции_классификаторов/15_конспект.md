## 15_лекция. Композиции классификаторов

Идея композиции заключается в том, что если мы хотим поточнее узнать длину палки. Мы должны измерять его несколько раз разными линейками и усреднять их. Даже если линейки не зависимы друг от друга, то дисперсия усреднения будет уменьшаться как корень квадартный от количества измерений ($$\sqrt{N}$$, N - количество измерений). 

В композиционной методике используется несколько алгоритмов для обучения на одной и той же выборке, что исходя из сказанного выше, должна уменьшать среднюю ошибку модели. 

* **Пример 1**: классификация на 2 класса, Y={-1,+1};
    $$a(x)=sign(b(x))$$
где R=R, b:X $$\rightarrow$$ R, c(b)$$\equiv$$sign(b)

* **Пример 2**: классификация на M классов Y = {1,...,M}:
    $$a(x)=argmax_{y\in Y}b_{y}(x)$$
где R=$$R^{M}$$, b: X $$\rightarrow R^{M}$$, C($$b_{1},...,b_{M}$$)$$\equiv argmax_{y\in Y b_{y}}$$

* **Пример 3**: регрессия, Y=R=*R*:
    C(b)$$\equiv$$b - решающее правило не нужно. 

Смесь алгоритмов (Mixture of Experts) - алгоритм заключается в предположении, что в своем подпространстве объектов определенные алгоритмы работают лучше. В своем роде, как эксперт в области своей компетенции. Эта компетенция зависит от X. Вместо весов используется функция, которая зависит от x. 

**Адаптивный буст (AdaBoost)**
Базовый алгоритм возвращает либо +1, либо -1. обобщение - возвращает 0, (лучше промолчать, чем соврать) не дает никакого вклада. 

Мы строим взвешенное голосование и берем его знак. 
$$a(x)=sign(\sum^{T}_{t=1})\alpha_{t}b(t)(x)$$, $$x\in X$$

Наша задача одновременно найти базовые алгоритмы $$b_{t}$$ и коэффициенты к нему $$\alpha_{t}$$. Такая задача очень сложна в исполнении, поэтому мы будем применять жадный алгоритм добавления для упрощения. Мы будем добавлять базовые алгоритмы в композицию по очереди, и каждый следующий должен компенсировать недостатки предыдущего. 

$$Q_{T}=\sum^{l}_{i=1}[y_{i}\sum^{T}_{t=1}\alpha_{i}b_{t}(x_{i})<0]$$

Две основные эвристики бустинга:
* фиксация базовых алгоритмов $$\alpha_{1}b_{1}(x),...,\alpha_{t-1}b_{t-1}(x)$$ при добавлении $$\alpha_{t}b_{t}(x)$$;
* гладкая аппроксимация пороговой функции потерь $$[M\leq 0]$$

**Алгоритм AdaBoost**

**Вход** Обучающая выборка $$X^{l}$$; параметр Т

**Выход** базовые алгоритмы и их веса $$\alpha_{t}b_{t}$$, t=1,...,T;
1) инициализировать веса объектов
$$w_{i}:=1/l, i=1,...,l$$

2) **для всех** t=1,...,T

3) обучить базовый алгоритм;
$$b_{t}:=argmin_{b} N(b;W^{l})$$

4) $$\alpha_{t}:=\frac{1}{2}ln\frac{1-N(b_{t};W^{l})}{N(b_{t};W^{l})}$$

5)  обновить веса объектов
$$w_{i}:=w_{i}exp(- \alpha_{t}y_{i}b_{t}(x_{i}))$$, i=1,...,l;


6) нормировать веса объектов
$$w_{0}:=\sum^{l}_{j=1}w_{j}$$
$$w_{i}:=w_{i}/w_{0}$$, i=1,...,t

AdaBoost имеет один единственный цикл. 
Вначале, мы говорим, что все объекты имеют одинаковые веса. Первйы базовый алгоритм решается так же, как и в обычном машинном обучении. Минимизируя ошибки и т.п. 

Далее, мы рассчитываем коэффициент $$\alpha$$ для нашего базового алгоритма. Затем обновляем веса объектов (шаг 5). Интерпретируется данный шаг довольно просто. Если наш базовый алгоритм ошибается, т.е. $$y_{i}b_{t}(x_{i})$$ будет отрицательным, то выражение под экспонентой будет положительным (мы полагаем, что параметр $$\alpha$$ всегда положителен) и, следовательно, вес следующего алгоритма будет выше. А, если оценка все лучше и лучше, то веса будут становиться все ниже и ниже, т.к. они уже работают и нам не надо на них настраиваться. 

## Эвристики и рекомендации

* Базовые классификаторы (weak classifier):
1) решающие деревья - используются чаще всего;
2) пороговые правила (data stumps), или пни, срубленные деревья: Это означает, что веток нет, есть только один корень, который сравнивается со значением порога:
   $$B = \{ b(x) = [f_{j}(x)>< \theta]|j=1,...,n, \theta \in R\}$$
3) для SVM бустинг не эффективен.

* Отсев шума: отбросить объекты с наибольшими $$w_{i}$$.
* Модификация формулы для $$\alpha_{t}$$ на случай N = 0:
  $$\alpha_{t}:= \frac{1}{2}\ln\frac{1-N(b_{t};W^{l})+\frac{1}{l}}{N(b_{t};W^{l})+\frac{1}{l}}$$
т.е. на случай, если базовый алгоритм не ошибается. Можно это интерпретировать, как то, что другие алгоритмы не нужны, базовый прекрасно справляется. Но, если алгоритм не ошибся на обучающей выборке, то это не значит, что он не ошибется на контрольной выборке. Для этого и используется байесовская частотная оценка. Необходимость в композиции не отпадает, даже если базовый алгоритм дает очень хорошую точность на обучающей выборке. 
* Дополнительный критерий остановки:
  увеличение частоты ошибок на контрольной выборке. На практике, число алгоритмов в композиции выбирается заранее, 300, 3000 или 30, взависимости от задачи. Теория утверждает, что при повышении сложности растет переобучение. Но с композициями такого не случалось, для этого надо было увеличить сложность еще сильнее (на порядок или на два порядка увеличить число T). Что является хорошим качеством, т.к. не надо слишком точно подбирать число T --- число базовых алгоритмов. 

37:04





