# Композиции классификиаторов. Часть II

**Стохастические методы построения композиций.**

Чтобы алгоритмы в композиции были различными
* их обучают по (случайным) подвыборкам
* либо по (случаынйм) подмножеством признаков.
 
**Первую идею** реализует *bagging* (bootstrap aggregation) [Breiman, 1996], причем подвыборки берутся длины l с возвращениями, как в методе bootstrap.

**Вторую идею** реализует RSM (random subspace method) [Duin, 2002]

Совместим обе идеи в одном алгоритме. 

F = {$$f_1,...,f_n$$} --- признаки
$$\mu(G,U)$$ --- метод обучения алгоритма по подвыборке U $$\subseteq X^l$$ использующий только признаки из G $$\subseteq$$ F

## Бэггинг и метод случайных подпространств

**Вход:** обучающая выборка $$X^l$$; параметры T
l' --- длина обучающих подвыборок;
n' --- длина признакового подописания;
$$\varepsilon_1$$ --- порог качества базовых алгоритмов на обучении;
$$\varepsilon_2$$ --- порог качества базовых алгоритмов на контроле. 

**Выход:** базовые алгоритмы $$b_t$$, t = 1,...,T;

1) для всех t = 1,...,T;
2)  U:=случайное подмножество $$X^l$$ длины l';
3)  G:=случаное подмножество G длины n';
4)  $$b_t := \mu(G,U)$$;
5)  если Q($$b_t$$, U) > $$\varepsilon_1$$ или Q($$b_t$$, $$X^l$$\U) > $$\varepsilon_2$$
6)  не включать $$b_t$$ в композицию;

Композиция --- простое голосование a(x) = C $$\left( \sum^{T}_{t=1} b_t(x)\right)$$

Несмотря на то, что в алгоритме написано для всех T, мы не обязаны выполнять их по порядку. В отличие от бустинга мы можем обучать наши базовые алгоритым в любом порядке, даже параллельно друг другу, что является одним из преимуществ данного алгоритма. 

Мы выбираем случайное подмножество объектов, случайное подмножество признаков, их длины --- это довольно хитрый параметр, от выбора которого очень многое зависит. Выбор качества композиции, также, является важным, т.к. если мы выберем его слишком высоким, то обучение затянется на очень долгое время, если выбираем слишком маленький, то ошибки будут очень большие. 

После обучения базовых алгоритмов получились различными, они оубчались на разных подвыборках, и никак не связаны с друг другом. Над ними будет проделано простое голосование, это была основная идея основополагающих работ бэггинга и методе случайных подпространств. Но никто не запрещает использовать взвешенное голосование, например SVM.  Ведь построенные базовые алгоритмы мы можем трактовать как признаки и добавить к ним веса. Любой линейный классификатор может нам построить взвешенное голосование. 

### Сравнение: boosting - bagging - RSM

* Бустинг лучше для больших обучающих выборок и для классов с границами сложной формы; *Бустинг требователен к длине выборке, чем длиннее тем лучше*
* Бэггинг и RSM лучше для коротких обучающих выборок;
* RSM лучше в тех случаях, когда признаков больше, чем объектов, или когда много неинформативных признаков; *Данный метод хорошо, когда у нас очень много признаков, и он случайно может выдать нам очень хорошую комбинацию признаков*
* Бэггинг и RSM эффективно распараллеливаются, бустинг выполняется строго последовательно.
 
**И еще несколько эмпирических наблюдений:**
* Веса алгоритмов не столь важны для выравнивания отступов;*можно не брать веса, а использовать метод простого голосования.*
* Веса объектов не столь важны для обеспечения различности;
* Короткие композиции из "сильных" алгоритмов типа SVM строить труднее, чем длинные из слабых. 

Небольшое развитиие бэггинга: ## Random Tree

Основные идеи:
* Бэггинг над решающими деревьями;
* признак в каждой вершине дерева выбирается из случайного подмножества k из n признаков;
* рекомендации:
    для регрессии k = [n/3];
    для класссификации k = [$$\sqrt{n}$$]

Основные свойсва:
* случайный лес --- один из самых сильных методов машинного обучения;
* обычно лишь немного уступает градиентному бустингу;
* но намного проще реализуется и распараллеливается
 
Считается, что случайный лес чуть уступает по качеству градиентному обучению (который считается самым успешным алгоритмом в машинном обучении), но реализуется намного проще. 

Для бэггинга размер выбираемого подмножества зависит от задачи и размера данных.. Если у вас миллион данных, то достаточно брать подмножества по 1000, можно без возвращения, если у вас 500, то берите меньше, но с возвращением. Возвращение --- это когда мы берем данные из обучающей выборки, но возвращаем их обратно, т.к. получается, что некоторые данные будут использоваться по несколько раз, а некоторые могут быть ни разу не использованы. В среднем, в бэггинге около 66% всех данных будет использовано. 


## Основые понятия и определения:

Задача регрессии: Y=R
Квадратичная функция потерь: L(y,a)=$$(a(x) - y)^2$$
Вероятностная постановка: $$X^l=(x_i,y_i)^l_{i=1} \sim p(x,y)$$
*предположение, что наша выборка приходит случайно независимо из одного и того же распределения парами объект--ответ*
Метод обучения: $$\mu:2^X \rightarrow A$$, т.е. выборка $$\rightarrow$$ алгоритм

Среднеквадратичный риск:

$$R(a) = E_{x,y}(a(x)-y)^2=\int_{X}\int_{Y}(a(x)-y)^2 p(x,y)dxdy$$ 

Минимум среднеквадратичного риска, "недостижимый идеал":

$$a*(x)=E(y|x)=\int_Y y p(y|x)dx$$

Основная мера качества метода обучения $$\mu$$:

$$Q(\mu)=E_{X^l}E_{y,y}(\mu(X^l)(x)-y)^2$$

$$\mu(X^l)$$ --- результат работы нашего обучения. В результате работы он дал некоторые алгоритм А, и его можно применить к объекту x. Поэтому и такая странная запись, две скобочки. Это означает, что по выборке $$X^l$$ был построен и обучен алгоритм и применен к объекту x. 

Если мы возьмем матожидание этой ошибки, то мы все еще получим случайное значение. Потому что она будет зависеть от выборки $$X^l$$ --- которая случайна. Поэтому здесь два источника случайности, какие то объекты x-y, которые выбираются случайно, и могут отсутствовать в обучающей выборке, они какие угодно. Поэтому мы сначала эту случайность уничтожаем при помощи мат ожидания x,y, а другую при помощи матожидания $$E_{X^l}$$. В результате получаем число, квадрат потерь при обучении по случайным подвыборкам и потом при тестировании на случайном объекте. 

Наша функция потерь --- матожидание, состоит из следующих частей (см. рисунок noise_variance_bias): неустранимый шум --- он есть всегда, не зависит от модели, зависит только от идеального алгорима; смещение (bias) --- это насколько средний ответ зависит от идеального ответа, это есть смещение модели, насколько модель не идеальна, средний ответ это если мы бесконечное число раз обучимся по случайным выборкам на одном объекте x; разброс (variance) --- как каждый алгоритм обученный по выборке $$X^l$$ примененный к объекту x ведет себя по отношение к среднему ответу, разброс будет равен 0, если у нас будет сверхстабильность, какой бы мы ни брали объект, у нас он был бы всегда равен среднему ответу. 


# Метод k ближайших соседей.

Вероятностная модель данных: p (y|x) = f(x) + N(0,$$\sigma^2$$)
Метод k ближайших соседей:

$$a(x) = \frac{1}{k}\sum^{k}_{j=1}y(x^{(j)})$$

где $$x^{(j)}$$ --- j-й сосед объекта x
a*(x)=f(x) --- истинная зависимость
$$\bar{a}(x)=\frac{1}{k}\sum^{k}_{j=1}f(x^{(j)})$$ --- средний ответ

Разложение bias-variance:

$$Q(\mu) = \underbrace{\sigma^2}_\text{шум} + \underbrace{E_{x,y}\left( \bar{a}(x) - f(x)\right)^2}_\text{смещение} + \underbrace{\frac{1}{k}\sigma^2}_\text{разброс}$$

шум мы убрать не можем, или уменьшить, мы ничего с ним сделать не можем. Рассмотрим смещение и разброс, мы можем уменьшить разброс увеличив число k --- число соседей. Смещение уменьшается, если мы уменьшим число k, что сделает нашу модель намного сложнее. У нас получается следующая картина: при уменьшении k --- модель усложняется, смещение уменьшается, а разброс увеличивается; при увеличении k --- модель усложняется, смещение увеличивается, а разброс уменьшается. 

## Простое голосование

Общее смещение композиций совпадает со смещением базового алгоритма. Т.к. смещение уменьшается в зависимости от сложности алгоритма, оправданно использование таких сложных базовых алгоритмов, как решающие деревья. 

Вариация в композициях состоит из двух членов, первый из которых уменьшается как $$\sqrt{T}$$, а второй член увеличивается из-за ковариации, т.е. если базовые алгоритмы не достаточно отличаются друг от друга. Такое свойство оправдывает сипользование метода случайных деревьев, которые позволяют построить композиции с достаточно отличающимися друг от друга базовыми алгоритмами. Но следует иметь в виду, что слишком низкая вариация это тоже плохо, может композиция получиться не достаточно сложной для правильного предсказывания объектов. 

Либо мало данных и много знаний о природе объектов и моделей, что позволит правильно подобрать семейство алгоритмов для описания этих объектов. Либо мало знаний и много данных. Использование более богатых, сложных, и универсальных моделей (типа нейронных сетей) может дать правильный результат. 


## Выводы. Почему бустинг и бэггинг работают?

* б\ггинг уменьшает вариацию
* бустинг уменьшает и смещение, и вариацию
* композиции тем менее эффективны, чем сильнее коррелируют базовые алгоритмы
* случайный лес уменьшает корреляции базовых алгоритмов.

При использовании смеси алгоритмов/экспертов (Mixture of Experts) следует иметь в виду, что если неправильно подобрать области компетенций для алгоритмов, то задача усложнится, а не упростится. 

## Вид функций компетентности

Функции компетентности выбираются из содержательных соображений и могут определяться:

* признаком f(x):
    $$g(x;\alpha,\beta) = \sigma(\alpha f(x) + \beta), \alpha, \beta \in R$$
* неизвестным направлением $$\alpha \in R^n:$$
    $$g(x;\alpha,\beta) = \sigma(x^T\alpha + \beta), \alpha \in R^n, \beta in R$$
* расстоянием до неизвестной точке $$\alpha \in R^n$$:
    $$g(x;\alpha,\beta) = exp(-\beta ||x-\alpha||^2), \alpha\in R^n, \beta \in R$$

где $$\alpha,\beta\in R$$ --- параметры, частично обучаемые по выборке
$$\sigma = \frac{1}{1+e^-z}$$ --- сигмоидная функция

Пример, задача с временными рамками. Есть магазин в котором некоторые товары продаются часто, некоторые редко --- раз в месяц. Логично предположить, что к этим товарам надо применять совершенно разные подходы. В таком случае вводим параметр частоты покупок, исходя из которого мы будем обрабатывать одни товары первым алгоритмом, другие товары вторым алгоритмом. В этом случае параметр частоты покупок будет служить индикатором сферы компетентности. 

Если нет эксперта, который может разделить вам обхекты, либо объекты не разделимы по линейным признакам, либо разделяются плохо, то не следует использовать алгоритм смеси экспертов. 

Для постройки базовых алгоритмов в смеси экспертов. Основная идея заключается в выпуклости функции потерь 

Функция потерь L(b,y) называется выпуклой по b, если $$\forall y'in Y, \forall b_1,b_2 \in R, \forall g_1,g_2 \geq 0: g_1+g_2 = 1$$ выполняется^

$$L(g_1b_1 + g_2b_2,y) \leq g_1L(b_1,y) + g_2L(b_2,y)$$

**Интерпретация:** потери растут не медленнее, чем величина отклонения от правильного ответа y

**Примеры** выпуклых функций потерь 

$$L(b,y)=\begin{cases}(b-y)^2 &\text{--- квадратичная (МНК-регрессия);}\\e^{-by}&\text{--- экспоненциальная (AdaBoost);}\\\log_{2}{(1+e^{-by})}&\text{--- логарифмическая (LR);}\\ (1-by)_+&\text{--- кусочно-линейная (SVM).}\end{cases}$$

Примерами не выпуклой функции являются пороговая функция. 

Свойство выпуклости позволяет оценить общую функцию потерь как сумму отдельных функций потерь каждого алгоритма. Тогда, при обучении мы сможем минимизоровать каждый алгоритм по отдельности, т.к. общая ошибка зависит от каждой индивидуальной ошибки. 

## Резюме

* Обучение смесей алгоритмов основано на принципе "разделяй и властвуй"
* Смесь алгоритмов имеет смысл строить в тех задачах, где есть априорные соображения о виде областей компетентности
* кроме последовательного метода построения смесей алгоритмов, известен еще иерархический. 
 















