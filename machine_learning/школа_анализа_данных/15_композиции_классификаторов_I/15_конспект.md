## 15_лекция. Композиции классификаторов

Идея композиции заключается в том, что если мы хотим поточнее узнать длину палки. Мы должны измерять его несколько раз разными линейками и усреднять их. Даже если линейки не зависимы друг от друга, то дисперсия усреднения будет уменьшаться как корень квадартный от количества измерений ($$\sqrt{N}$$, N - количество измерений). 

В композиционной методике используется несколько алгоритмов для обучения на одной и той же выборке, что исходя из сказанного выше, должна уменьшать среднюю ошибку модели. 

* **Пример 1**: классификация на 2 класса, Y={-1,+1};
    $$a(x)=sign(b(x))$$
где R=R, b:X $$\rightarrow$$ R, c(b)$$\equiv$$sign(b)

* **Пример 2**: классификация на M классов Y = {1,...,M}:
    $$a(x)=argmax_{y\in Y}b_{y}(x)$$
где R=$$R^{M}$$, b: X $$\rightarrow R^{M}$$, C($$b_{1},...,b_{M}$$)$$\equiv argmax_{y\in Y b_{y}}$$

* **Пример 3**: регрессия, Y=R=*R*:
    C(b)$$\equiv$$b - решающее правило не нужно. 

Смесь алгоритмов (Mixture of Experts) - алгоритм заключается в предположении, что в своем подпространстве объектов определенные алгоритмы работают лучше. В своем роде, как эксперт в области своей компетенции. Эта компетенция зависит от X. Вместо весов используется функция, которая зависит от x. 

**Адаптивный буст (AdaBoost)**
Базовый алгоритм возвращает либо +1, либо -1. обобщение - возвращает 0, (лучше промолчать, чем соврать) не дает никакого вклада. 

Мы строим взвешенное голосование и берем его знак. 
$$a(x)=sign(\sum^{T}_{t=1})\alpha_{t}b(t)(x)$$, $$x\in X$$

Наша задача одновременно найти базовые алгоритмы $$b_{t}$$ и коэффициенты к нему $$\alpha_{t}$$. Такая задача очень сложна в исполнении, поэтому мы будем применять жадный алгоритм добавления для упрощения. Мы будем добавлять базовые алгоритмы в композицию по очереди, и каждый следующий должен компенсировать недостатки предыдущего. 

$$Q_{T}=\sum^{l}_{i=1}[y_{i}\sum^{T}_{t=1}\alpha_{i}b_{t}(x_{i})<0]$$

Две основные эвристики бустинга:
* фиксация базовых алгоритмов $$\alpha_{1}b_{1}(x),...,\alpha_{t-1}b_{t-1}(x)$$ при добавлении $$\alpha_{t}b_{t}(x)$$;
* гладкая аппроксимация пороговой функции потерь $$[M\leq 0]$$

**Алгоритм AdaBoost**

**Вход** Обучающая выборка $$X^{l}$$; параметр Т

**Выход** базовые алгоритмы и их веса $$\alpha_{t}b_{t}$$, t=1,...,T;
1) инициализировать веса объектов
$$w_{i}:=1/l, i=1,...,l$$

2) **для всех** t=1,...,T

3) обучить базовый алгоритм;
$$b_{t}:=argmin_{b} N(b;W^{l})$$

4) $$\alpha_{t}:=\frac{1}{2}ln\frac{1-N(b_{t};W^{l})}{N(b_{t};W^{l})}$$

5)  обновить веса объектов
$$w_{i}:=w_{i}exp(- \alpha_{t}y_{i}b_{t}(x_{i}))$$, i=1,...,l;


6) нормировать веса объектов
$$w_{0}:=\sum^{l}_{j=1}w_{j}$$
$$w_{i}:=w_{i}/w_{0}$$, i=1,...,t

AdaBoost имеет один единственный цикл. 
Вначале, мы говорим, что все объекты имеют одинаковые веса. Первый базовый алгоритм решается так же, как и в обычном машинном обучении. Минимизируя ошибки и т.п. 

Далее, мы рассчитываем коэффициент $$\alpha$$ для нашего базового алгоритма. Затем обновляем веса объектов (шаг 5). Интерпретируется данный шаг довольно просто. Если наш базовый алгоритм ошибается, т.е. $$y_{i}b_{t}(x_{i})$$ будет отрицательным, то выражение под экспонентой будет положительным (мы полагаем, что параметр $$\alpha$$ всегда положителен) и, следовательно, вес следующего алгоритма будет выше. А, если оценка все лучше и лучше, то веса будут становиться все ниже и ниже, т.к. они уже работают и нам не надо на них настраиваться. 

## Эвристики и рекомендации

* Базовые классификаторы (weak classifier):
    1) решающие деревья - используются чаще всего;
    2) пороговые правила (data stumps), или пни, срубленные деревья: Это означает, что веток нет, есть только один корень, который сравнивается со значением порога:
   $$B = \{ b(x) = [f_{j}(x)>< \theta]|j=1,...,n, \theta \in R\}$$
    3) для SVM бустинг не эффективен.

* Отсев шума: отбросить объекты с наибольшими $$w_{i}$$.
* Модификация формулы для $$\alpha_{t}$$ на случай N = 0:
  $$\alpha_{t}:= \frac{1}{2}\ln\frac{1-N(b_{t};W^{l})+\frac{1}{l}}{N(b_{t};W^{l})+\frac{1}{l}}$$
т.е. на случай, если базовый алгоритм не ошибается. Можно это интерпретировать, как то, что другие алгоритмы не нужны, базовый прекрасно справляется. Но, если алгоритм не ошибся на обучающей выборке, то это не значит, что он не ошибется на контрольной выборке. Для этого и используется байесовская частотная оценка. Необходимость в композиции не отпадает, даже если базовый алгоритм дает очень хорошую точность на обучающей выборке. 
* Дополнительный критерий остановки:
  увеличение частоты ошибок на контрольной выборке. На практике, число алгоритмов в композиции выбирается заранее, 300, 3000 или 30, взависимости от задачи. Теория утверждает, что при повышении сложности растет переобучение. Но с композициями такого не случалось, для этого надо было увеличить сложность еще сильнее (на порядок или на два порядка увеличить число T). Что является хорошим качеством, т.к. не надо слишком точно подбирать число T --- число базовых алгоритмов. 

## Обоснование бустинга

Давайте ужесточим понятие ошибки, и будем считать, что ошибка это когда отступ меньше $$\theta$$

$$\nu_{\theta}(a,X^{l})=\frac{1}{l}\sum^{l}_{i=1}[b(x_{i}y_{i})\leq\theta], \theta>0$$
Ошибка это не когда мы пересекли границу двух классов, а ошибка когда мы к ней приблизились на величину $$\theta$$
Обычная частота ошибок $$\nu_{0}(a,X^{l}) \leq \nu_{\theta}(a,X^{l})$$

**Теорема (Freund, Schapire, Bartlett, 1998)**
Если $$|B|<\infty$$, то $$\forall\theta > 0, \forall\eta\in (0,1)$$ с вероятностью $$1-\eta$$
если мы пользуемся не слишком богатым семейством алгоритмов, то справедливо вероятностное неравенство. Вероятность близка к единице (т.к. мы вправе предполагать, что $$\eta$$ будет маленьким $$\sim5\%$$): 

$$P[ya(x)<0]\leq \nu_{\theta}(a,X^{l})+C\sqrt{\frac{ln{|B|}ln{l}}{l\theta^{2}}+\frac{1}{l}\ln{\frac{1}{\eta}}}$$

Слева стоит вероятность ошибки --- отступ для нашей композиции. Верхняя оценка определяется частотой ошибок на нашей выборке, доля объектов с отступом меньше чем $$\theta$$, + штрафное слагаемое. Самое любопытное свойство штрафного слагаемого заключается в том, что он не зависит от T --- числа базовых алгоритмов. Но, он зависит от сложности базового семейства алгоритмов, что, кстати, оправдывает использование решающих пней и прочих идиотстких конструкций. 

Если рассмотреть другой параметр, от которого зависит неравенство $$\theta$$, то при его увеличении штрафное слагаемое уменьшается, а частота ошибок увеличивается. Поэтому можно минимизировать данное выражение по $$\theta$$, чтобы получить его оптимальное значение. Для удовлетворения такого условия алгоритм должен увеличивать отступ. Т.е. сделать распределение отступов таким, чтобы для большинства этих объектов отступ становился все больше и больше. Оказывается, в этом и заключаается замечательное свойство бустинга. Он как бы раздвигает классы в  пространстве растущей размерности.  


**Основной вывод:** оценка не зависит от T явно. Голосование не увеличивает сложность, эффективной используемого множества алгоритмов. 


* С ростом T распределение отступов сдвигается вправо, то есть бустинг "раздвигает" классы в пространстве векторов растущей размерности;
* значит, в оценке можно уменьшить второй член, увеличив $$\theta$$ и не изменив $$\nu_{\theta} (a, X^{l})$$;
* Можно уменьшить второй член, если уменьшить |B|, то есть взять простое семейство базовых алгоритмов. 

Основным недостатком AdaBoost является то, что алгоритм слишком жесткий. Слишком жестко наказывает за ошибки и, как следствие, начинает обучаться на ошибках. Если, к примеру, у нас были выбросы, то алгоритм начинается обучаться на них, и мы получим неправильную оценку. 

# Градиентный бустинг для произвольной функции потерь 
Friedman G. Greedy Function Approximation: A gradent boosting machine, 1999. 

Линейная (выпуклая) комбинация базовых алгоирмтов:

$$a(x)=\sum^{T}_{t=1}\alpha_{t}b_{t}(x). x\in X, \alpha_{t}\in R$$

В отличие от AdaBoost, тут нет никаких ограничений у базовых алгоритмов, они могут принимать любое значение, а не только {-1;0;+1}

$$Q(\alpha, b; X^{l})=\sum^{l}_{i=1}L(\underbrace{\underbrace{\sum^{T-1}_{t=1}\alpha_{t}b_{t}}_{\text{$f_{T-1,i}$}}+\alpha b(x_{i}),y_{i}}_\text{$f_{T,i}$})\rightarrow min_{a,b}$$

$$f_{T-1,i}=(f_{T-1,i})^{l}_{i=1}$$ - текущее приближение
$$f_{T,i}=(f_{T,i})^{l}_{i=1}$$ - следующее приближение

**Алгоритм градиентного бустинга (Gradient Boosting)**

**Вход** Обучающая выборка $$X^{l}$$; параметр Т

**Выход** базовые алгоритмы и их веса $$\alpha_{t}b_{t}$$, t=1,...,T;
1) инициализировать веса объектов
$$w_{i}:=1/l, i=1,...,l$$

2) **для всех** t=1,...,T

3) найти базовый алгоритм, приближающий градиент:

    $$b_{t}:=argmin_{b} \sum^{l}_{i=1}(b(x_{i})+L'(f_{i},y_{i}))^{2}$$;

4) решить задачу одномерной минимизации:
    $$\alpha_{t}:=argmin_{\alpha>0}\sum^{l}_{i=1}L(f_{i}+\alpha b_{t}(x_{i},y_{i}))$$;

5)  обновить значения композиции на объектах выборки:
    $$f_{i}:=f_{i}+\alpha_{t}b_{t}(x_{i})$$; i=1,...,t
    
Здесь, L - это любая функция потерь, на усмотрение разработчика. 

## Стохастический градиентный бустинг (SGB):

**Идея**: на шагах 3-5 использовать не всю выборку $$X^{l}$$, а случайную подвыборку без возвращений

**Преимущества:**
* улучшается качество;
* улучшается сходимость;
* уменьшается время обучения. 

## **Резюме:**

* Градиентный бустинг - наиболее общий из всех бустингов:
-- произвольная функция потерь;
-- произвольное пространство оценок R;
-- подходит для регрессии, классификации, ранжирования.

* Стохастический вариант SGB --- лучше и быстрее

* Чаще всего GB применяется к решающим деревьям

* Градиентный бустинг над ODT = Yandex MatrixNet

**Несколько эмпирических наблюдений**
* Веса алгоритмов не столь важны для выравнивания отступов;
* Веса объектов не столь важны для обеспечения различности;
* Не удается строить короткие композиции из "сильных" алгоритмов типа SVM (только длинные из слабых)

## Простое голосование в задачах классификации

Возьмем Y = {$$\pm 1$$}, $$F(b_{1},...,b_{T}=\frac{1}{T}\sum^{T}_{t=1}b_{t}. C(b)=sign(b)$$. 
*Будем строить простое голосование для двухклассовой задачи. Никаких ограничений к базовому алгоритму*

Функционал качества композиции --- число ошибок на обучении:

$$Q(a,X^{l}) = \sum^{l}_{i=1}[y_{i}a(x_{i}<0)]=\sum^{l}_{i=1}[\underbrace{y_{i}b_{1}(x_{i}+...+y_{i}b_{T}(x_{i}))}_{\text{$M_{iT}$}}]$$
*Мы хотим минимизировать число ошибок. Для этого мы должны добавить к отступу еще один алгоритм, который бы максимально увеличивал отступы. Отицательные отстуты должны стать положительными, но сильно положительные могут слегка уменьшиться (мы готовы пожертвовать ими). Т.е. мы занимаемся выравниваем распределения отступов.* (**p.s. это похоже на идею использования другой функции активайии в машинном обучении вместо сигмоидной функции, про которую говорил Andrew Ng. Идея заключалась в том, чтобы сгладить промежуточные оценки, т.к. у сигмоида в задачах классификации значения близкие к нулю лежат на прямой.)**

$$M_{iT} = y_{i}b_{1}(x_{i}+...+y_{i}b_{T}(x_{i}))$$ - отступ (margin)  объекта $$x_{i}$$

**Эвристика**: чтобы $$b_{t+1}$$ компенсировал ошибки композиции:

$$Q(b,U) = \sum_{x_{i} \in U} [y_{i}b(x_{i})<0]\rightarrow min_{b}$$

где U  ={$$x_{i}: M_{0} < M_{it} \leq M_{1}$$}

$$M_{0}, M_{1}$$ - параметры метода обучения

## Алгоритм ComBoost (Committee Boosting)

**Вход:** обучающая выборка $$X^{l}$$; параметры $$T_{0}, l_0, l_1, l_2, \Delta t$$
**Выход**: $$b_1,...,b_T$$
1) $$b_1 = argmin_b Q(b, X^{l})$$;
    упорядочить $$X^l$$ по возрастанию $$M_i = y_ib_t(x_i), i=1,...,l$$;
2) **для всех** t=1,...,T
    3)  **для всех** $$k=l_1,...,l_2$$ с шагом $$\Delta l$$
        4) $$U=\{x_i\in X^l: l_0\leq i \leq k\}$$;
        5) $$b_{tk}:=argmin_b Q(b,U)$$;
        
    6) 6--- выбрать наилучший $$b_i \in \{ b_{tk}\}$$  по критерию Q;
    7) 7--- обновить отступы: $$M_i := M_i + y_ib_t(x_i), i = 1,...,l$$;
    8) 8--- упорядочить выборку $$X^l$$ по возрастанию отступов $$M_i$$;
    9) 9--- опция: скорректировать значения параметров $$l_0,l_1,l_2$$

10) 10---**пока** Q существенно улучшается. 

Можно по разному пытаться корректировать параметры алгоритма. Можно вообще выполнять этот алгоритм вручную, т.к. он заточен на то, чтобы сделать оценку из небольшого числа хороших алгоритмов, например SVM. Если у вас уже есть один SVM, и вы хотите улучшить его добавив еще 1,2,3 SVM но не слишком много, то данный алгоритм подойдет идеально. 

## Обобщение для задач с произвольным числом классов

*такой же подход может быть использован и для градиентного бустинга*

Пусть теперь у нас задача классификации с произвольным числом классов Y = {$$1,..,M$$}

*Чтобы перейти к многоклассовой классификации надо просто поменять формулу, которая рассчитывает отступы.*

Композиция - простое голосование, причем каждый базовый алгоритм $$b_{yt}$$ голосует только за свой класс y: *т.е. базовые классы двухклассовые*

$$a(x) = argmax_{y\in Y}\Gamma_{y_i}(x_i)$$ $$\Gamma_y(x)=\frac{1}{|T_y|}\sum_{t \in T}b_{yt}(x)$$

*$$\Gamma_y(x)$$ --- оценка степени принадлежности объекта x к классу y. Чем большое величина, тем выше шанс того, что он принадлежит к классу y*

В алгоритме только два изменения
--- изменится определение отступа $$M_i$$

$$M_{i} = \Gamma_{y_i}(x_i) - max_{y \in Y\{y_i\}}\Gamma_y(x_i)$$


*Отступ вычисляется как оценка степени принадлежности за свой и правильный класс минус максимальная оценка за неправильный класс. Если эта штука положительна, то значит нет ошибки*

--- в алгоритме ComBoost на шаге 3 придется решать за какой класс строить очередной базовый алгоритм, кроме того, немного изменится шаг 7 (пересчет отступов)

*Еще одна особенность базовые классы. Теперь они еще связаны со своим классом. Т.е. как бы, каждый класс старается отделить свой класс от всех остальных*

## Резюме
* ComBoost --- простой метод обучения композиций, способный строить короткие композиции из хороших базовых алгоритмов;

* Недостатки ComBoost --- приходится подбирать параметры индивидуально для каждой задачи;

* Обобщение ComBoost:
--- много классов вместо двух;
--- взвешенное голосование вместо простого. 



