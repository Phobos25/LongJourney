{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb35c1d6",
   "metadata": {},
   "source": [
    "# Convert tabular data to image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d76693",
   "metadata": {},
   "source": [
    "Sometimes it's easier to work with convolutional network. Since it provides very good accuracy, sometimes even better than random forest, or XGBoost. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2cf87",
   "metadata": {},
   "source": [
    "we are going to use tab2img library\n",
    "\n",
    "Look [here](https://github.com/nicomignoni/tab2img) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1efddcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tab2img\n",
      "  Using cached tab2img-0.0.2-py3-none-any.whl (4.8 kB)\n",
      "Installing collected packages: tab2img\n",
      "Successfully installed tab2img-0.0.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install tab2img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f6348",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cb7c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from tab2img.converter import Tab2Img\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b3072",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a312942",
   "metadata": {},
   "source": [
    "We are going to use titanic dataset, for no particular reason\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466f6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/titanic/train.csv\")\n",
    "test_data  = pd.read_csv(\"data/titanic/test.csv\")\n",
    "\n",
    "#replace NaN with 0\n",
    "train_data.fillna(0,inplace=True)\n",
    "test_data.fillna(0,inplace=True)\n",
    "\n",
    "# drop useless columns\n",
    "train_data = train_data.drop(columns=['Name','Cabin','Embarked', 'Ticket'])\n",
    "train_data['TFamily'] = train_data['SibSp'] + train_data['Parch']\n",
    "train_data = train_data.drop(columns=['SibSp', 'Parch'])\n",
    "\n",
    "test_data = test_data.drop(columns=['Name','Cabin','Embarked', 'Ticket'])\n",
    "test_data['TFamily'] = test_data['SibSp'] + test_data['Parch']\n",
    "test_data = test_data.drop(columns=['SibSp', 'Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae74386",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['Survived'])\n",
    "Y = train_data['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c85ae",
   "metadata": {},
   "source": [
    "We need to convert 'sex' column into 1 and 0, where 1 --- stands for male, and 0 --- stands for female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7d30213",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for sex in X['Sex']:\n",
    "    if sex == 'male':\n",
    "        arr.append(1)\n",
    "    else:\n",
    "        arr.append(0)\n",
    "X['Sex'] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "804adb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data split function\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "315dcb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the x for train and valid\n",
    "xtrain,xvalid,ytrain,yvalid = train_test_split(X,Y,train_size=0.80,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061be8c",
   "metadata": {},
   "source": [
    "### Convert to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f959ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tab2Img()\n",
    "images_train = model.fit_transform(xtrain.to_numpy(), ytrain)\n",
    "images_valid = model.transform(xvalid.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b0360d",
   "metadata": {},
   "source": [
    "Now we have images to work with. We can use CNN or any other model to work with thi data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e800c81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.7208,   0.    ,   1.    ],\n",
       "        [ 40.    ,  31.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       [[ 16.7   ,   2.    ,   3.    ],\n",
       "        [  4.    ,  11.    ,   0.    ],\n",
       "        [  0.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       [[  9.    ,   0.    ,   3.    ],\n",
       "        [ 47.    , 874.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 49.5042,   0.    ,   1.    ],\n",
       "        [ 71.    , 494.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       [[221.7792,   0.    ,   1.    ],\n",
       "        [  0.    , 528.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       [[ 25.925 ,   0.    ,   1.    ],\n",
       "        [  0.    , 169.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b927d057",
   "metadata": {},
   "source": [
    "### keras with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfa8650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da6826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2926f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16dec4fe",
   "metadata": {},
   "source": [
    "### fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a440c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c20a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a1445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0a99a06",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee953be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "#блокируем всплавание о предупреждениях\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd2fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, \n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting 'normalize=True'\n",
    "    '''\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,i, cm[i,j],\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i,j] > thresh else 'black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61090bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 3, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2310a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #входной слой\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(224,224,3)),\n",
    "    #этот слой урезает картинку вдвое. \n",
    "    MaxPool2D(pool_size=(2,2), strides=2),    \n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    #переводим все измерения матрицы в одну плоскость. \n",
    "    Flatten(),\n",
    "    #выходной слой. Т.к. у нас только 2 класса, мы используем units=2\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2db5dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 401410    \n",
      "=================================================================\n",
      "Total params: 420,802\n",
      "Trainable params: 420,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cfbbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a91aa811",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = tf.convert_to_tensor(images_train)\n",
    "images_valid = tf.convert_to_tensor(images_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15268db3",
   "metadata": {},
   "source": [
    "надо бы посмотреть, почему tab2img вообще нуждается в таргете. для чего он его использует? \n",
    "\n",
    "прогнать пример, который там приводится. \n",
    "\n",
    "возможно исопльзовать что-то другое.\n",
    "\n",
    "* можно попробовать вывести рисунок\n",
    "\n",
    "* наверное надо сделать flatten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be9370f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1132\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_split:\n\u001b[0;32m   1126\u001b[0m   \u001b[38;5;66;03m# Create the validation data using the training data. Only supported for\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m   \u001b[38;5;66;03m# `Tensor` and `NumPy` input.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   (x, y, sample_weight), validation_data \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1129\u001b[0m       data_adapter\u001b[38;5;241m.\u001b[39mtrain_validation_split(\n\u001b[0;32m   1130\u001b[0m           (x, y, sample_weight), validation_split\u001b[38;5;241m=\u001b[39mvalidation_split))\n\u001b[1;32m-> 1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data:\n\u001b[0;32m   1133\u001b[0m   val_x, val_y, val_sample_weight \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1134\u001b[0m       data_adapter\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(validation_data))\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39m_should_use_with_coordinator:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1007\u001b[0m, in \u001b[0;36m_EagerTensorBase.__bool__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "model.fit(x=images_train, validation_data=images_valid, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67215941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1db39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4ab7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864ee91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d93828d",
   "metadata": {},
   "source": [
    "### Bonus section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00eb72f",
   "metadata": {},
   "source": [
    "As a bonus, let's use XGBoost and compare our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfe446",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdbc07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
