{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение\n",
    "\n",
    "Логистическая регрессия — один из видов линейных классификаторов. Одной из ее особенностей является возможность оценивания вероятностей классов, тогда как большинство линейных классификаторов могут выдавать только номера классов.\n",
    "\n",
    "Логистическая регрессия использует достаточно сложный функционал качества, который не допускает записи решения в явном виде (в отличие от, например, линейной регрессии). Тем не менее, логистическую регрессию можно настраивать с помощью градиентного спуска.\n",
    "\n",
    "Мы будем работать с выборкой, содержащей два признака. Будем считать, что ответы лежат в множестве {-1, 1}. Для настройки логистической регрессии мы будем решать следующую задачу:\n",
    "\n",
    "$\\frac{1}{l}\\sum^{l}_{i=1}log(1+exp(-y_i(w_1x_{i1}+w_2x_{i2})))+\\frac{1}{2}C||w||^2 \\rightarrow min_{w_1,w_2}$\n",
    "\n",
    "Здесь xi1 и xi2 — значение первого и второго признаков соответственно на объекте xi. В этом задании мы будем рассматривать алгоритмы без свободного члена, чтобы упростить работу.\n",
    "\n",
    "Градиентный шаг для весов будет заключаться в одновременном обновлении весов w1 и w2 по следующим формулам (проверьте сами, что здесь действительно выписана производная нашего функционала):\n",
    "\n",
    "$w_1:=w_1+k\\frac{1}{l}\\sum^{l}_{i=1}y_ix_{i1}\\left( 1-\\frac{1}{1+exp(-y_1(w_1x_i1+w_2x_{i2}))}\\right)-kCw_1$\n",
    "\n",
    "$w_2:=w_2+k\\frac{1}{l}\\sum^{l}_{i=1}y_ix_{i1}\\left( 1-\\frac{1}{1+exp(-y_1(w_1x_i1+w_2x_{i2}))}\\right)-kCw_2$\n",
    "\n",
    "\n",
    "Здесь k — размер шага.\n",
    "\n",
    "Линейные методы могут переобучаться и давать плохое качество из-за различных проблем в данных: мультиколлинеарности, зашумленности и т.д. Чтобы избежать этого, следует использовать регуляризацию — она позволяет понизить сложность модели и не допустить переобучения. Сила регуляризации определяется коэффициентом C в формулах, указанных выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data-logistic.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[0]\n",
    "X = data[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([0,0])\n",
    "k=0.1\n",
    "l = len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def gradient_descent(X,y,w,k,l,C):\n",
    "    #gradient descent\n",
    "    w = w + k*1/l*np.sum(np.dot(np.dot(X.T,y),(1-sigmoid(np.dot(X,w))).T),axis=1)-k*C*w.T\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0.1\n",
    "l = len(X)\n",
    "C = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is (205, 2)\n",
      "y shape is (205, 1)\n",
      "w shape is (2, 1)\n"
     ]
    }
   ],
   "source": [
    "w = np.array([0,0]).reshape(2,1)\n",
    "y = np.array(y).reshape(205,1)\n",
    "X = np.array(X)\n",
    "#sanity check\n",
    "print(f'X shape is {X.shape}')\n",
    "print(f'y shape is {y.shape}')\n",
    "print(f'w shape is {w.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "w = w + (k*1/l*np.sum(np.dot(np.dot(X.T,y),(1-sigmoid(np.dot(X,w))).T),axis=1)-k*C*w.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.sum(np.dot(np.dot(X.T,y),(1-sigmoid(np.dot(X,w))).T),axis=1)/l*k - k*C*w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# решение взято с интернета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9355238095238094\n",
      "0.9355238095238094\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import math\n",
    "\n",
    "rawData = pd.read_csv('data-logistic.csv', header=None)\n",
    "X_ = rawData.values[:,1:]\n",
    "y_ = rawData.values[:,:1].T[0]\n",
    "\n",
    "w = np.array([0,0]).reshape(2,1)\n",
    "y_ = np.array(y).reshape(205,1)\n",
    "X_ = np.array(X)\n",
    "\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1.0/1+np.exp(-x)\n",
    "\n",
    "def distance(a,b):\n",
    "    return np.sqrt(np.square(a[0]-b[0])+np.square(a[1]-b[1]))\n",
    "\n",
    "def log_regression(X,y,k,w,C, epsilon, max_iter):\n",
    "    \n",
    "    w1,w2 = w\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        w1new = w1 + k*np.mean(y*X[:,0]*(1-(1./(1+np.exp(-y*(w1*X[:,0]+w2*X[:,1]))))))-k*C*w1\n",
    "        w2new = w2 + k*np.mean(y*X[:,0]*(1-(1./(1+np.exp(-y*(w1*X[:,0]+w2*X[:,1]))))))-k*C*w2\n",
    "        if distance((w1new,w2new),(w1,w2)) < epsilon:\n",
    "            break\n",
    "        w1,w2 = w1new,w2new\n",
    "        \n",
    "    predictions = []\n",
    "    for i in range(len(X)):\n",
    "        t1 = -w1*X[i,0] - w2*X[i,1]\n",
    "        s = sigmoid(t1)\n",
    "        predictions.append(s)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "p0 = log_regression(X_,y_, 0.1, w, 0, 0.00001, 10000)\n",
    "p1 = log_regression(X_,y_, 0.1, w, 10, 0.00001, 10000)\n",
    "\n",
    "print(sklearn.metrics.roc_auc_score(y,p0))\n",
    "print(sklearn.metrics.roc_auc_score(y,p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
