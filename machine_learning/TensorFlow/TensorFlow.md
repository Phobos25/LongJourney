# Tensor Flow

Tensor Flow это открытая библиотека для работы с deep learning. 

# Computer vision
Для компьютера изображение выглядит как 2D матрица из чисел от 0 до 255. Это для чернобелых изображений. Для цветных будет 3D матрица с глубиной 3 (RGB). Для обучения нашего алгоритма используется так называемый convolution --- это матрица, которая ищет определенные паттерны в нашем рисунке. Нам самим его задавать не надо, модель сама должна подобрать. 
Пример convolution:
```
 1.5  1.5
-1.5 -1.5
```
Такая матрица ведет поиск горизонтальной линии на рисунке. Для горизонтальной линии эта матрица будет давать значение намного выше 0, а для вертикальных или если линия вообще отсутствует будет давать значение ближе к 0. 

После создания фильтра мы получаем выходной тензор, в котором выделены нужные нам паттерны. Каждый слой выходного тензора результат одного фильтра, мы можем использовать очень много фильтров, чтобы найти более сложные паттерны. Многие современные модели содержат тысячи фильтров и способны найти очень интересные паттерны, машины, пешеходов, светофоры и т.д.

# Дообучение моделей
В туториалах и практических занатиях во время обучения часто используют веса уже обученных моделей. Такой подход понятен, т.к. обучать модели очень долго, но когда студенты хотят применить модели к задачам классификации немного другого характера, например, если хотят разделить фотографии на городские и лесные, модели не будут работать. Т.к. модели не классифицировали на такие специфические задачи. Можно, конечно, поискать готовые обученные модели такие, либо самому обучить модель, но для этого надо тысячи вручную классифицированных фотографий. В такие моменты используется, т.н. **дообучение**. Видите ли, модель состоит из множества слоев, и нижние слои ищут очень простые закономерности --- вертикальные линии, горизонтальные линии, изменение цветов и т.п., и только более верхние начинают искать более сложные закономерности, т.е. используется более сложные фильтры больших размеров. И только самый последний слой классифицирует рисунки. Поэтому для нашей задачи, мы выбросим самый последний слой и заменим на свою, новую классификацию. Для этого нам надо классифицировать фотографии на предмет, насколько они городские, и насколько они лесные. 

В классификациях с двумя классами часто возникает желание классифицировать только на 1 класс, а если не подходит к первому классу, фотография автоматически относится ко второму. Ни в коем случае так не делайте, т.к. в будущем, если понадобится добавить еще один класс, вам придется все делать заново и, вероятно, полностью менять логику/алгоритм вашей модели. С точки зрения повторного применения кода и объектно-ориентированного программирования это неправильно. Если вы разделите на два класса, то при добавлении третьего, вам не придется менять предыдущие два класса, а просто добавить третий класс. Говоря по простому вы снижаете свою будущую работу на 30%, или будете использовать в будущем 50-70% вашего кода. 

Рассмотрим на примере кода:
```
from tensorflow.python.keras.models import Sequential
from tensorflow.python.kreas.layers import Dense

weights_path = '../input/resnet50/resnet50_weights,tf_dim_ordering_tf_kernels_notop...'
num_classes = 2

my_new_model = Sequential()
my_new_model.add(ResNet50 (include_top=False,
                           weights=weights_path,
                           pooling='avg'))
my_new_model.add(Dense(num_classes, activation='softmax'))

my_new_model.layers[0].trainable = False
```

"include_top=False" --- означает, что мы убираем последний слой, который классифицировал данные

"my_new_model.layers[0].trainable = False" --- указывает, что не надо обучать загруженный слой, т.к. мы используем уже обученную модель, обучать ее заново нам не надо. 

Начало работы с практикой

# Data Augmentation

Один из простых и действенных способов для увеличения количества данных, это использовать метод Data Augmentation. К примеру, если у нас есть изображение города, даже если мы отзеркалим его --- зеркально перевернем --- это все еще будет изображение города. Используя данный метод, можно увеличить число изображений почти вдвое. Следует заметить, что не всегда разумно зеркалить изображения, особенно если мы имеем дело с текстом, как знак "STOP" к примеру, или с номерами автомобилей. 

Еще один метод, это смещение рисунка по вертикали или горизонтали. Который очень целесообразно использовать в задачах с текстовым изображением. Хотя, можно использовать и для нашей задачи классификации --- город или сельская местность. 

Код:
```
data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input, 
                   horizontal_flip=True,
                   width_shift_range = 0.2,
                   height_shift_range= 0.2)
```
Здесь, preprocessing_function=preprocess_input --- это и есть смещение, horizontal_flip=True --- зеркальное переворачивание, width_shift_range и height_shift_range --- величина смещения по горизонтали и вертикали. 

# Backpropagation
Метод обратных ошибок заключается в том, чтобы при обычном обучении сохранять некоторые результатвы вычислений для последующего их использования. При обычном методом "forward propagation" веса меняются на последнем слое, а при обратноых ошибках эти веса используются для изменения весов в обратную сторону по всем слоям.  

# patterns in backward flow
add gate: gradient distributor. *Если стоит "+ gate", то локальный градиент будет одинаковым.* (см рис) 
max gate: gradient router. *Если стоит "max gate", то один из локальных градиентов --- который меньше --- зануляется --- умножается на 0, другой --- который больше --- умножается на 1*

# Implementation: forward/backward API

Graph (or Net) object. (Rough pseudo code)
```
class ComputationalGraph(object):
    #...
    def forward(inputs):
        # 1. [pass inputs to input gates...]
        # 2. forward the computational graph:
        for gate in self.graph.nodes_topologically_sorted():
            gate.forward()
        return loss # the final gate in the graph outputs the loss
    def backward():
        for gate in reversed(self.graph.nodes_topologically_sorted()):
            gate.backward() # little piece of backprop (chain rule applied)
        return inputs_gradients
```

```
x
    *   Z
y
class MultiplyGate (object)
    def forward (x,y):
        z = x*y
        return z
    def backward(dz):
        # dx = ... #todo
        # dy = ... #todo
        return [dx,dy]
```
```
class MultiplyGate (object)
    def forward (x,y):
        z = x*y
        self.x = x # must save these values for backward prop
        self.y = y  
        return z
        
    def backward(dz):
        dx = self.y * dz # [dz/dx * dL/dz]
        dy = self.x * dz # [dz/dy * dL/dz]
        return [dx,dy]
```

При FP следует запомнить значения дифференциалов, т.к. они будут нужны для BP. 
Следует иметь в виду, что gate, про который мы здесь писали --- это то же самое, что и layer --- слой. 
Нейросети это просто куча слоев, которое сгруппирированы тем или иным способом. Этот способ, зависит от решаемой задачи. Если приводить аналогию --- это как кусочки лего, из которых мы можем создавать разные конструкции. Где каждый кусочек лего --- это отдельно взятый слой. 

Для любой нейросети используется и FP и BP, FP --- рассчитывает функцию потерь (loss), BP --- рассчитывает градиент (gradient), а затем модель, используя градиенты обновляет веса (weights). 

https://github.com/BVLC/caffe --- это открытый фреймворк DeepLearning, который в основном используется для обработки изображений. 

# short summary
* neural nets will be very large no hope of writing down gradient formula by hand for all parameters
* backpropagation = recursive application of the chain rule along a computational graph to compute the gradients of all inputs/parameters/intermediates
* implementations maintain a graph structure, where the nodes implement the **forward()/backward()** API
* **forward** compute result of an operation and save any intermediates needed for gradient computation in memory
* **backward** apply the chain rule to compute the gradient of the loss function with respect to the inputs. 

# Part 2
Работая с ConvNet надо иметь в виду, что можно работать и с малым объемом данных. Т.к. для таких данных используется уже обученная модель, и надо слегка подправить модель, чтобы модель работала с новыми данными или классифицировала нечто другое. 

Надо иметь в виду, что обучение такой модели как ConvNet это очень затратно с точки зрения процессорных мощностей, поэтому если вы работаете с моделью в качестве обучения, то лучше работать с небольшими данными и уже обученной моделью. Т.к. большая часть работы инженера - ученого данных это именно настройка выходных данных, классификации, то чем обычно и занимаются во время обучения. 
17:00
