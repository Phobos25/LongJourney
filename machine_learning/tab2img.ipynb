{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddbaa2d1",
   "metadata": {},
   "source": [
    "# Convert tabular data to image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e60d2",
   "metadata": {},
   "source": [
    "Sometimes it's easier to work with convolutional network. Since it provides very good accuracy, sometimes even better than random forest, or XGBoost. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdcadb",
   "metadata": {},
   "source": [
    "we are going to use tab2img library\n",
    "\n",
    "Look [here](https://github.com/nicomignoni/tab2img) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1249df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tab2img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a20960a",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cb7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from tab2img.converter import Tab2Img\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b625a2",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf3bef9",
   "metadata": {},
   "source": [
    "We are going to use titanic dataset, for no particular reason\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c7d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/titanic/train.csv\")\n",
    "test_data  = pd.read_csv(\"data/titanic/test.csv\")\n",
    "\n",
    "#replace NaN with 0\n",
    "train_data.fillna(0,inplace=True)\n",
    "test_data.fillna(0,inplace=True)\n",
    "\n",
    "# drop useless columns\n",
    "train_data = train_data.drop(columns=['Name','Cabin','Embarked', 'Ticket'])\n",
    "train_data['TFamily'] = train_data['SibSp'] + train_data['Parch']\n",
    "train_data = train_data.drop(columns=['SibSp', 'Parch'])\n",
    "\n",
    "test_data = test_data.drop(columns=['Name','Cabin','Embarked', 'Ticket'])\n",
    "test_data['TFamily'] = test_data['SibSp'] + test_data['Parch']\n",
    "test_data = test_data.drop(columns=['SibSp', 'Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14fe2dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['Survived'])\n",
    "Y = train_data['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66329513",
   "metadata": {},
   "source": [
    "We need to convert 'sex' column into 1 and 0, where 1 --- stands for male, and 0 --- stands for female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e41f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for sex in X['Sex']:\n",
    "    if sex == 'male':\n",
    "        arr.append(1)\n",
    "    else:\n",
    "        arr.append(0)\n",
    "X['Sex'] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15eafd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data split function\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451044af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the x for train and valid\n",
    "xtrain,xvalid,ytrain,yvalid = train_test_split(X,Y,train_size=0.80,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea556b5",
   "metadata": {},
   "source": [
    "### Convert to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b40f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tab2Img()\n",
    "images_train = model.fit_transform(xtrain.to_numpy(), ytrain)\n",
    "images_valid = model.transform(xvalid.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c78b1",
   "metadata": {},
   "source": [
    "Now we have images to work with. We can use CNN or any other model to work with thi data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95323628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.7208,   0.    ,   1.    ],\n",
       "        [ 40.    ,  31.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       [[ 16.7   ,   2.    ,   3.    ],\n",
       "        [  4.    ,  11.    ,   0.    ],\n",
       "        [  0.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       [[  9.    ,   0.    ,   3.    ],\n",
       "        [ 47.    , 874.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 49.5042,   0.    ,   1.    ],\n",
       "        [ 71.    , 494.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       [[221.7792,   0.    ,   1.    ],\n",
       "        [  0.    , 528.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]],\n",
       "\n",
       "       [[ 25.925 ,   0.    ,   1.    ],\n",
       "        [  0.    , 169.    ,   0.    ],\n",
       "        [  1.    ,   0.    ,   0.    ]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70c9d7",
   "metadata": {},
   "source": [
    "### keras with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a39a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7eeaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fb597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526ed136",
   "metadata": {},
   "source": [
    "### fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078667a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91500868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4580b7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfcd263d",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4abd2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "#блокируем всплавание о предупреждениях\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46be3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, \n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting 'normalize=True'\n",
    "    '''\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,i, cm[i,j],\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i,j] > thresh else 'black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8b5f5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 3, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb33329a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Igor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    #входной слой\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(224,224,3)),\n",
    "    #этот слой урезает картинку вдвое. \n",
    "    MaxPool2D(pool_size=(2,2), strides=2),    \n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    #переводим все измерения матрицы в одну плоскость. \n",
    "    Flatten(),\n",
    "    #выходной слой. Т.к. у нас только 2 класса, мы используем units=2\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f15ca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 401410    \n",
      "=================================================================\n",
      "Total params: 420,802\n",
      "Trainable params: 420,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1924eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0feeee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_train = tf.convert_to_tensor(images_train)\n",
    "# images_valid = tf.convert_to_tensor(images_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87984a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 10 column where imags are placed\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42a2dc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1\n",
      " 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0\n",
      " 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0\n",
      " 0 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0\n",
      " 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1\n",
      " 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "plotImages(images_train)\n",
    "print(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93399484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1643a105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df6b43f6",
   "metadata": {},
   "source": [
    "надо бы посмотреть, почему tab2img вообще нуждается в таргете. для чего он его использует? \n",
    "\n",
    "прогнать пример, который там приводится. \n",
    "\n",
    "возможно исопльзовать что-то другое.\n",
    "\n",
    "* можно попробовать вывести рисунок\n",
    "\n",
    "* наверное надо сделать flatten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d09a98",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_input to have 4 dimensions, but got array with shape (712, 3, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a6f48333d338>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2651\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2653\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    374\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_input to have 4 dimensions, but got array with shape (712, 3, 3)"
     ]
    }
   ],
   "source": [
    "model.fit(x=images_train, y=ytrain, validation_split=0.2, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada29015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd2e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae118b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf57cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b84eed6f",
   "metadata": {},
   "source": [
    "### Bonus section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a23fd3",
   "metadata": {},
   "source": [
    "As a bonus, let's use XGBoost and compare our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf71d2",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955c122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57cc56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
