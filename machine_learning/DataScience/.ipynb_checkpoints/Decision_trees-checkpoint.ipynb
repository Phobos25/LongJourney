{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "\n",
    "* Работает, как для задач регрессии, так и для классификации;\n",
    "* Разделяет данные на определенные регионы. Набор правил разделения может быть выражено в виде дерева;\n",
    "\n",
    "* Одно дерево обычно ничем не лучше линейной регрессии, логистической регрессии или ЛДА;\n",
    "* Бэггинг, случайные деревья, и бустинг могут существенно улучшить эффективность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression tree\n",
    "\n",
    "* Divide the predictor space into J distinct and non-overlapping regions\n",
    "\n",
    "* for every observation that falls in a region, predict the mean of the response value in that region\n",
    "\n",
    "* Each region is split to minimize the RSS (residual sum of squares)\n",
    "\n",
    "* It uses a top-down greedy approach called **recursive binary splitting**\n",
    "\n",
    "#### Top-down greedy approach\n",
    "* Top-down: all observations are in a single region before the first split\n",
    "\n",
    "* Greedy: the best split occurs at particular step to make the best prediction at that step, rather than looking forward and making a split that will give a better result in a future step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R_1 (j,s)$ = {$X| X_j$ < s} and $R_2$(j,s) = {$X | X_j \\geq$ s}\n",
    "\n",
    "and we seek j and s to minimize:\n",
    "\n",
    "$\\sum_{i:x_i\\in R_1(j,s)}(y_i - \\hat{y}_{R_1})^2 + \\sum_{i:x_i\\in R_2(j,s)} (y_i - \\hat{y}_{R_2})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification tree\n",
    "\n",
    "* Predict the most commonly occuring class in a region\n",
    "\n",
    "* RSS cannot be used; each split must minimize the **classification error rate**\n",
    "\n",
    "#### Classification error rate. \n",
    "***Gini index***\n",
    "\n",
    "$G = \\sum^{K}_{k=1}\\hat{p}_{mk}(1-\\hat{p}_{mk})$\n",
    "\n",
    "* small if proportion is close to 0 or 1. Good measure of **node purity**\n",
    "\n",
    "***Cross-entropy***\n",
    "\n",
    "$D = -\\sum^{K}_{k=1}\\hat{p}_{mk}\\log{(\\hat{p}_{mk})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "* Bagging: bootstrap aggregation\n",
    "\n",
    "Основная идея использования бэггинга заключается в том, что у деревья выбора обычно очень высокая вариация, что приводит к оверфиту. Бэггинг уменьшает вариацию, тем самым улучшая эффективность нашей модели\n",
    "\n",
    "### Boosting\n",
    "\n",
    "* Похож на бэггинг, но деревья строятся друг за другом, причем каждое последующее дерево использует информацию предыдущего дерева\n",
    "\n",
    "* медленная обучаемость\n",
    "\n",
    "* each tree fist the residuals instead of the target variable. Each tree is small and will slowly improve the predictions\n",
    "\n",
    "Используется 3 параметра для настройки:\n",
    "* число деревьев **(B)**: бустинг может начать оверфитить, если B слишком большой. Используйте кросс-калибровку\n",
    "\n",
    "* shrinkage parameter $**(\\alpha)**$: значение которое контролирует темп обучения (learning rate). Принимает значения между 0.01 и 0.001\n",
    "\n",
    "* Число деления (splits) в каждом дереве **(d)**: контролирует сложность ансамбля моделей, который подвергается бустингу. d=1, это стандартное значение. Также известно под названием **interaction depth**\n",
    "\n",
    "``\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "boost_clf = GradientBoostingClassifier(\n",
    "    \n",
    "    learning_rate = 0.01, // shrinkage parameter \n",
    "    \n",
    "    n_estimators = 100,   // number of trees B\n",
    "    \n",
    "    max_depth = 2         // number of splits d\n",
    ")\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
