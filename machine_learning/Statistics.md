# Statistics. Linear regression
 
В линейной регрессии обычно используется МНК для построения фита. Сам метод заключается в том, чтобы найти такой фит, при котором сумма квадратов отклонения точек от фита была бы минимальной:

$$\sum = \frac{(\bar{x} - x)^2}{n} \rightarrow min$$

Для оценки качества МНК используют $$R^2$$. Чем меньше это значение тем лучше. 

$$R^2 = \frac{D(mean) - D(fit)}{D(mean)}$$, где D(mean) --- это дисперсия от среднего, а D(fit) --- дисперсия от аппроксимации. 

Интиутивно можно сказать, что $$R^2$$ показывает насколько хорошо аппроксимация описывает данные. 

### Maximum likelihood

Если рассматривать функцию максимума правдоподобия для нормального распределения для n-точек, то мы получим следующую формулу:

$$L(\mu, \sigma| x_1,..., x_n) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x_1-\mu}{\sigma})^2}\times ... \times \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x_n-\mu}{\sigma})^2}$$

для нахождения оптимальной величины для среднего $$\mu$$ и стандарного отклонения $$\sigma$$ мы продифференцируем эту формулу. Тогда получится:

$$\frac{\partial}{\partial\mu}ln[L(\mu,\sigma|x_1,...,x_n)] = \frac{1}{\sigma^2}[(x_1+...+x_n)-n\mu]$$ (1)

$$\frac{\partial}{\partial\sigma}ln[L(\mu,\sigma|x_1,...,x_n)] = \frac{n}{\sigma}+\frac{1}{\sigma^3}[(x_1-\mu)^2+...+(x_n-\mu)^2]$$ (2)

Далее, для нахождения пика максимального правдоподобия, мы должны решить привести эти уравнения к 0 и решить их. Что даст нам оптимальное значения для $$\mu$$ и $$\sigma$$.

При решении получаем:
$$\mu = \frac{(x_1+...+x_n)}{n}$$
$$\sigma = \sqrt{\frac{(x_1-\mu)^2+...+(x_n-\mu)^2}{n}}$$

т.е. среднее арифметическое и стандартное отклонение.